{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "94zkjiqa36Nk"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "MODEL_PATH = \"models/\"\n",
    "num_workers = 4\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NYTevtra31qK",
    "outputId": "2eb8ee2e-c395-442a-df8b-ce98542fab44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: editdistance in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.5.3)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLLr2IHE42As"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import *\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import sys\n",
    "import editdistance\n",
    "import pickle\n",
    "import random\n",
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqjm3FY74QPL"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "# set SEED\n",
    "os.environ[\"SEED\"] = \"999\"\n",
    "torch.manual_seed(999)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "pcdduNHj_mGx",
    "outputId": "605b3e74-283f-43ee-c767-a7e8b7d938d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  3 23:58:08 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla T4            On   | 00000000:00:1E.0 Off |                    0 |\r\n",
      "| N/A   49C    P0    27W /  70W |    662MiB / 15109MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1950      C   ...u/anaconda3/envs/pytorch_p36/bin/python   651MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaboD8CfCVuY"
   },
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self):\n",
    "        self.char2idx = {}\n",
    "        self.char_list = []\n",
    "        self.size = 0\n",
    "\n",
    "    def add_char(self, char):\n",
    "        if not char in self.char2idx:\n",
    "            self.char2idx[char] = self.size\n",
    "            self.char_list.append(char)\n",
    "            self.size += 1\n",
    "\n",
    "    def __call__(self, char):\n",
    "        if not char in self.char2idx:\n",
    "            return self.char2idx['<unk>']\n",
    "        return self.char2idx[char]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erQhNzdiERJ_"
   },
   "outputs": [],
   "source": [
    "def build_vocab(overwrite = True):\n",
    "    vocab_file = DATA_PATH + 'vocab.pkl'\n",
    "    # if file exist then load files\n",
    "    if os.path.exists(vocab_file) and (overwrite == False):\n",
    "        print (\"loading pre-extracted vocabulary\")\n",
    "        vocab = pickle.load(open(DATA_PATH + 'vocab.pkl', 'rb'))\n",
    "        return vocab\n",
    "\n",
    "    print (\"Loading data...\")\n",
    "    #dev_transcripts = np.load(DATA_PATH+\"dev_transcripts.npy\", allow_pickle=True)\n",
    "    transcripts = np.load(DATA_PATH+\"train_transcripts.npy\", allow_pickle=True)\n",
    "    #transcripts = np.append(transcripts, dev_transcripts)\n",
    "    print(\"Loaded data.\")\n",
    "\n",
    "    vocab = Vocabulary()\n",
    "    vocab.add_char('<pad>')\n",
    "    vocab.add_char('<sos>')\n",
    "    vocab.add_char('<eos>')\n",
    "    vocab.add_char('<unk>')\n",
    "    vocab.add_char(' ')\n",
    "\n",
    "    for s in transcripts:\n",
    "        for w in s:\n",
    "            for c in w.decode():\n",
    "                vocab.add_char(c)\n",
    "\n",
    "    print(\"Total character size: {}\".format(len(vocab)))\n",
    "    pickle.dump(vocab, open(vocab_file, 'wb'))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8CF62CHFHsf-",
    "outputId": "afdcae09-1ef5-44ee-f6e7-fe0d1345bf90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded data.\n",
      "Total character size: 36\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "s6TruEKlI8U0",
    "outputId": "42b52403-704a-450e-ce96-e8fbc261d983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>', '<sos>', '<eos>', '<unk>', ' ', 'T', 'H', 'E', 'F', 'M', 'A', 'L', 'P', 'R', 'O', 'D', 'U', 'C', 'S', 'I', 'W', 'Y', 'N', 'G', 'V', 'B', 'K', 'Q', 'X', 'J', 'Z', '-', \"'\", '.', '_', '+']\n"
     ]
    }
   ],
   "source": [
    "print (vocab.char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hcUJOQLyAWtc"
   },
   "outputs": [],
   "source": [
    "def load_data(x_path,y_path=\"\"):\n",
    "    x = np.load(x_path, allow_pickle=True,encoding='bytes')\n",
    "    print (\"X:\")\n",
    "    print (\"Number of utterances \" + str(x.shape[0]))\n",
    "    print (\"Number of dimentions \" + str(x[0].shape[1]))\n",
    "    print (\"Avg length of utterances \" + str(np.mean([i.shape[0] for i in x])))\n",
    "    if y_path:\n",
    "        print (\"Y:\")\n",
    "        transcripts = np.load(y_path, allow_pickle=True,encoding='bytes')\n",
    "        #print (transcripts)\n",
    "        y = []\n",
    "        for s in transcripts:\n",
    "            new = []\n",
    "            new.append(vocab(\"<sos>\"))\n",
    "            for w in s:\n",
    "                for c in w.decode():\n",
    "                    new.append(vocab(c))\n",
    "                new.append(vocab(\" \"))\n",
    "            new.append(vocab(\"<eos>\"))\n",
    "            y.append(np.array(new))\n",
    "        y = np.array(y)\n",
    "        print (\"Avg length of transcripts in char \" + str(np.mean([i.shape[0] for i in y])))\n",
    "        return x, y\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "78n6vyObAZyw",
    "outputId": "8eb9a741-9ff1-4ce5-ebeb-2526eeec7792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "Number of utterances 1106\n",
      "Number of dimentions 40\n",
      "Avg length of utterances 626.7793851717902\n",
      "Y:\n",
      "Avg length of transcripts in char 100.27305605786619\n"
     ]
    }
   ],
   "source": [
    "dev_x, dev_y = load_data(DATA_PATH+\"dev_new.npy\",y_path=DATA_PATH+\"dev_transcripts.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FoSYkNY7AlL9",
    "outputId": "a8d62b83-b3b1-4b69-e241-c1d7ea31c0a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iqZjcBKyLy0M"
   },
   "outputs": [],
   "source": [
    "class Speech2TextDataset(Dataset):\n",
    "    '''\n",
    "    Dataset class for the speech to text data, this may need some tweaking in the\n",
    "    getitem method as your implementation in the collate function may be different from\n",
    "    ours. \n",
    "    '''\n",
    "    def __init__(self, speech, text=None, isTrain=True):\n",
    "        self.speech = speech\n",
    "        self.isTrain = isTrain\n",
    "        if (isTrain):\n",
    "            self.text = text\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.speech.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if (self.isTrain == True):\n",
    "            return torch.tensor(self.speech[index].astype(np.float32)), torch.tensor(self.text[index])\n",
    "        else:\n",
    "            return torch.tensor(self.speech[index].astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sh4WgLVrP50_"
   },
   "outputs": [],
   "source": [
    "def collate_pad(batch):\n",
    "    batch_size = len(batch)\n",
    "    #order = list(range(batch_size))\n",
    "    #batch = zip(batch, order)\n",
    "    #batch = sorted(batch, key=lambda x: x[0][0].shape[0], reverse=True) # sort, decreasing seq length\n",
    "    #order = [i[1] for i in batch]\n",
    "    #batch = [i[0] for i in batch]\n",
    "    if len(batch[0]) == 2:\n",
    "        x, y = zip(*batch)\n",
    "    else:\n",
    "        x = batch\n",
    "        y = None\n",
    "    \n",
    "    x_len = torch.LongTensor([i.shape[0] for i in x])\n",
    "    x = pad_sequence(x)\n",
    "    if y != None:\n",
    "        y_len = torch.LongTensor([i.shape[0] for i in y])\n",
    "        y = pad_sequence(y)\n",
    "        return x, x_len, y, y_len\n",
    "    else:\n",
    "        return x, x_len#, order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "847W_bmyRbBR"
   },
   "outputs": [],
   "source": [
    "dev_dataloader = DataLoader(Speech2TextDataset(dev_x, dev_y), \n",
    "                            shuffle=False, \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            collate_fn = collate_pad,\n",
    "                            pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRB-ZICeh0d7"
   },
   "outputs": [],
   "source": [
    "#train_dataloader = dev_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Stw0ZspfRZey",
    "outputId": "be792b5e-2167-432c-9e60-9582abb3aa7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "Number of utterances 24724\n",
      "Number of dimentions 40\n",
      "Avg length of utterances 651.3022164698269\n",
      "Y:\n",
      "Avg length of transcripts in char 105.88023782559456\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(DATA_PATH+\"train_new.npy\",y_path=DATA_PATH+\"train_transcripts.npy\")\n",
    "train_dataloader = DataLoader(Speech2TextDataset(train_x, train_y), \n",
    "                              shuffle=True, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              collate_fn = collate_pad,\n",
    "                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wXtC7Jukn647",
    "outputId": "36d120e0-3639-4c5c-f23b-a1ed0dd1d74b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "956Jj2rCQS8p",
    "outputId": "7cc8b75a-294b-4a54-e17e-ef1115efc85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1350, 64, 40])\n",
      "tensor([ 552,  744,  435,  893,  375,  516,  606,  515,  437,  515,  627,  575,\n",
      "         557,  790,  197,  394,  642, 1017,  594,  565,  496,  593, 1073,  373,\n",
      "         752,  619, 1175, 1030,  776,  836,  198, 1350,  593,  400, 1101, 1233,\n",
      "         806,  846,  490,  659,  898,  523, 1151,  532,  540,  552,  980,  947,\n",
      "         713,  627,  888,  780,  605,  954,  977,  384,  621,  312,  736,  627,\n",
      "         381,  516,  578, 1101])\n",
      "torch.Size([209, 64])\n",
      "tensor([ 84, 108,  73, 145,  73,  82,  90,  84,  70,  91, 111,  83, 101, 152,\n",
      "         21,  76,  83, 160,  94,  94,  82, 106, 166,  52, 102, 124, 169, 150,\n",
      "        138, 112,  26, 188,  89,  53, 139, 184, 133, 150,  87, 120, 168,  89,\n",
      "        209,  78,  79,  90, 163, 174, 136,  91, 134, 154, 121, 163, 153,  52,\n",
      "        126,  55, 134,  86,  49,  78,  88, 176])\n"
     ]
    }
   ],
   "source": [
    "for x, x_len, y, y_len in train_dataloader:\n",
    "    print (x.shape) #T, batch, in_dim\n",
    "    print (x_len)\n",
    "    print (y.shape) #T, batch\n",
    "    print (y_len)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4DdmiKfigVhF"
   },
   "outputs": [],
   "source": [
    "class pBLSTM(nn.Module):\n",
    "    '''\n",
    "    Pyramidal BiLSTM\n",
    "    The length of utterance (speech input) can be hundereds to thousands of frames long.\n",
    "    The Paper reports that a direct LSTM implementation as Encoder resulted in slow convergence,\n",
    "    and inferior results even after extensive training.\n",
    "    The major reason is inability of AttendAndSpell operation to extract relevant information\n",
    "    from a large number of input steps.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(pBLSTM, self).__init__()\n",
    "        self.blstm = nn.LSTM(input_size=input_dim * 2, hidden_size=hidden_dim, num_layers=1, bidirectional=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        :param x : (L * N * in_dim) input to the pBLSTM --> packed\n",
    "        :return output: (L, N, H) encoded sequence from pyramidal Bi-LSTM \n",
    "        '''\n",
    "        x, lengths = pad_packed_sequence(x)\n",
    "        x = x.transpose(0, 1).contiguous() #N * T * in_dim\n",
    "\n",
    "        T = x.shape[1]\n",
    "        \n",
    "        if T % 2 != 0:\n",
    "            T -= 1\n",
    "            x = x[:, :T, :]\n",
    "        x = x.view(x.shape[0], T//2, x.shape[2] * 2).contiguous()\n",
    "        #x = x.contiguous().view(x.shape[0], T//2, 2, x.shape[2])\n",
    "        #x = torch.mean(x, dim=3) # N, T//2 * in_dim*2\n",
    "        x = x.transpose(0, 1).contiguous() # T//2 * N * in_dim*2\n",
    "        x = pack_padded_sequence(x, lengths//2, enforce_sorted=False)\n",
    "        output = self.blstm(x)[0]\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7aSiWzkO-qyq"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    '''\n",
    "    Attention is calculated using key, value and query from Encoder and decoder.\n",
    "    Below are the set of operations you need to perform for computing attention:\n",
    "        energy = bmm(key, query)\n",
    "        attention = softmax(energy)\n",
    "        context = bmm(attention, value)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "    def forward(self, query, key, value,lengths):\n",
    "        '''\n",
    "        :param query :(N, context_size) Query is the output of LSTMCell from Decoder\n",
    "        :param key: (T, N, key_size) Key Projection from Encoder per time step\n",
    "        :param value: (T, N, value_size) Value Projection from Encoder per time step\n",
    "        :return output: Attended Context\n",
    "        :return attention_mask: Attention mask that can be plotted  \n",
    "        '''\n",
    "        key = key.transpose(0,1)#(N, T, key_szie)\n",
    "        value = value.transpose(0,1)#(N, T, value_size)\n",
    "        attention = torch.bmm(key, query.unsqueeze(2)).squeeze(2) #(batch_size, max_len)\n",
    "        mask = torch.arange(key.size(1)).unsqueeze(0) < lengths.unsqueeze(1)\n",
    "        mask = mask.cuda()\n",
    "        attention = nn.functional.softmax(attention, dim=1)\n",
    "        attention = mask.float()*attention\n",
    "        attention = F.normalize(attention, dim=1, p=1)\n",
    "\n",
    "        out = torch.bmm(attention.unsqueeze(1), value).squeeze(1)\n",
    "\n",
    "        return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Bh91xZxCXYQ"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    '''\n",
    "    Encoder takes the utterances as inputs and returns the key and value.\n",
    "    Key and value are nothing but simple projections of the output from pBLSTM network.\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, value_size=128,key_size=128):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.blstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True)\n",
    "        \n",
    "        ### Add code to define the blocks of pBLSTMs! ###\n",
    "        pBLSTMs = [pBLSTM(hidden_dim * 2, hidden_dim),\n",
    "                   pBLSTM(hidden_dim * 2, hidden_dim),\n",
    "                   pBLSTM(hidden_dim * 2, hidden_dim)]\n",
    "        self.pBLSTMs = torch.nn.ModuleList(pBLSTMs)\n",
    "\n",
    "        self.key_network = nn.Linear(hidden_dim*2, value_size)\n",
    "        self.value_network = nn.Linear(hidden_dim*2, key_size)\n",
    "\n",
    "    def forward(self, x, lens):\n",
    "        rnn_inp = pack_padded_sequence(x, lengths=lens, batch_first=False, enforce_sorted=False)\n",
    "        outputs, _ = self.blstm(rnn_inp) #outputs: L x N x H*2\n",
    "\n",
    "        ### Use the outputs and pass it through the pBLSTM blocks! ###\n",
    "        for pBLSTM in self.pBLSTMs:\n",
    "            outputs = pBLSTM(outputs) \n",
    "\n",
    "        linear_input, lens = pad_packed_sequence(outputs)\n",
    "        keys = self.key_network(linear_input)\n",
    "        value = self.value_network(linear_input)\n",
    "\n",
    "        return keys, value, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ub_OyLybGlQL"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    '''\n",
    "    As mentioned in a previous recitation, each forward call of decoder deals with just one time step, \n",
    "    thus we use LSTMCell instead of LSLTM here.\n",
    "    The output from the second LSTMCell can be used as query here for attention module.\n",
    "    In place of value that we get from the attention, this can be replace by context we get from the attention.\n",
    "    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance.\n",
    "    '''\n",
    "    def __init__(self, vocab_size, hidden_dim, value_size=128, key_size=128, isAttended=True):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim, padding_idx=0)\n",
    "        self.lstm1 = nn.LSTMCell(input_size=hidden_dim + value_size, hidden_size=hidden_dim)\n",
    "        self.lstm2 = nn.LSTMCell(input_size=hidden_dim, hidden_size=key_size) #query\n",
    "        self.query_layer = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.isAttended = isAttended\n",
    "        if (isAttended == True):\n",
    "            self.attention = Attention()\n",
    "\n",
    "        self.character_prob = nn.Linear(key_size + value_size, vocab_size)\n",
    "\n",
    "    def forward(self, key, values, lengths, text=None, isTrain=True, tf = 0.3):\n",
    "        '''\n",
    "        :param key :(T, N, key_size) Output of the Encoder Key projection layer\n",
    "        :param values: (T, N, value_size) Output of the Encoder Value projection layer\n",
    "        :param text: (N, text_len) Batch input of text with text_length\n",
    "        :param isTrain: Train or eval mode\n",
    "        :return predictions: Returns the character perdiction probability \n",
    "        '''\n",
    "        #print (\"key\")\n",
    "        #print (key.shape) #130 64 128\n",
    "        #print (\"values\")\n",
    "        #print (values.shape)\n",
    "        batch_size = key.shape[1]\n",
    "\n",
    "        if (isTrain == True):\n",
    "            #print (\"txt\")\n",
    "            #print (text.shape)\n",
    "            max_len =  text.shape[0]\n",
    "            embeddings = self.embedding(text) #[L, N, dim]\n",
    "            #print (\"embeddings\")\n",
    "            #print (embeddings.shape) \n",
    "        else:\n",
    "            max_len = 250\n",
    "\n",
    "        predictions = []\n",
    "        hidden_states = [None, None]\n",
    "        attentions = []\n",
    "        prediction = torch.ones(batch_size,1).cuda()\n",
    "        context=values[0,:,:]\n",
    "        for i in range(max_len - 1):\n",
    "            # * Implement Gumble noise and teacher forcing techniques \n",
    "            # * When attention is True, replace values[i,:,:] with the context you get from attention.\n",
    "            # * If you haven't implemented attention yet, then you may want to check the index and break \n",
    "            #   out of the loop so you do you do not get index out of range errors. \n",
    "            if (isTrain):\n",
    "                if random.random() < tf:\n",
    "                    char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "                else:\n",
    "                    char_embed = embeddings[i,:,:]\n",
    "            else:\n",
    "                char_embed = self.embedding(prediction.argmax(dim=-1))\n",
    "\n",
    "            inp = torch.cat([char_embed, context], dim=1)\n",
    "            #print ('inp')\n",
    "            #print (inp.shape)\n",
    "            hidden_states[0] = self.lstm1(inp, hidden_states[0])\n",
    "            \n",
    "            inp_2 = hidden_states[0][0]\n",
    "            #print (\"inp_2\")\n",
    "            #print (inp_2.shape)\n",
    "            hidden_states[1] = self.lstm2(inp_2, hidden_states[1])\n",
    "            \n",
    "            output = hidden_states[1][0]\n",
    "            ### Compute attention from the output of the second LSTM Cell ###\n",
    "            query = self.query_layer(output)\n",
    "            if self.isAttended:\n",
    "                context, attention = self.attention(query, key, values, lengths)\n",
    "                attentions.append(attention.detach())\n",
    "\n",
    "            prediction = self.character_prob(torch.cat([output, context], dim=1)) #N*V\n",
    "            predictions.append(prediction.unsqueeze(1))\n",
    "  \n",
    "        return torch.cat(predictions, dim=1), torch.stack(attentions) #short_in_dim * N * out_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vNOkgw_Gd4mq"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    '''\n",
    "    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder.\n",
    "    This is simply a wrapper \"model\" for your encoder and decoder.\n",
    "    '''\n",
    "    def __init__(self, input_dim, vocab_size, hidden_dim, value_size=128, key_size=128, isAttended=True):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim)\n",
    "        self.decoder = Decoder(vocab_size, hidden_dim)\n",
    "\n",
    "    def forward(self, speech_input, speech_len, text_input=None, isTrain=True, tf = 0.3):\n",
    "        key, value, lengths = self.encoder(speech_input, speech_len)\n",
    "        if (isTrain == True):\n",
    "            predictions, attentions = self.decoder(key, value, lengths, text=text_input, tf = tf)\n",
    "            \n",
    "        else:\n",
    "            predictions, attentions = self.decoder(key, value, lengths, isTrain=False, tf = tf)\n",
    "        return predictions, attentions\n",
    "        \n",
    "\n",
    "def init_model(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight.data)\n",
    "        nn.init.normal_(m.bias.data)\n",
    "    if isinstance(m, nn.LSTMCell) or isinstance(m, nn.GRUCell):\n",
    "        for name, param in m.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            if 'bias' in name:\n",
    "                nn.init.normal_(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "yWq3A5kFBpEz",
    "outputId": "7a2f2b5f-81ca-41fe-e8c0-ce0f7ea21986"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq(\n",
      "  (encoder): Encoder(\n",
      "    (blstm): LSTM(40, 128, bidirectional=True)\n",
      "    (pBLSTMs): ModuleList(\n",
      "      (0): pBLSTM(\n",
      "        (blstm): LSTM(512, 128, bidirectional=True)\n",
      "      )\n",
      "      (1): pBLSTM(\n",
      "        (blstm): LSTM(512, 128, bidirectional=True)\n",
      "      )\n",
      "      (2): pBLSTM(\n",
      "        (blstm): LSTM(512, 128, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "    (key_network): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (value_network): Linear(in_features=256, out_features=128, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(36, 128, padding_idx=0)\n",
      "    (lstm1): LSTMCell(256, 128)\n",
      "    (lstm2): LSTMCell(128, 128)\n",
      "    (query_layer): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (attention): Attention()\n",
      "    (character_prob): Linear(in_features=256, out_features=36, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq(input_dim=40, vocab_size=len(vocab), hidden_dim=128)\n",
    "model.apply(init_model)\n",
    "model = model.cuda()\n",
    "print (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(MODEL_PATH+'1588543810_3.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N0R1cCGcA_h7"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1, threshold=0.1, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss(reduction = 'none').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2OtiQMRd4BqT"
   },
   "outputs": [],
   "source": [
    "def get_distance(predict,real):\n",
    "    distance = 0\n",
    "    total = len(predict)\n",
    "    for i in range(total):\n",
    "        distance += editdistance.eval(predict[i], real[i])\n",
    "    return distance/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6n3ANPOlMYdL"
   },
   "outputs": [],
   "source": [
    "def plot_weights(attentions, epoch):\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(attentions, interpolation='nearest', cmap='hot')\n",
    "    fig.savefig(\"epoch%d.png\" % (epoch))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdkN8ra-NHTy"
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_grad_flow(parameters):\n",
    "    ave_grads = []\n",
    "    max_grads = []\n",
    "    layers = []\n",
    "    for n, p in parameters:\n",
    "        if p.requires_grad and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads) + 1, lw=2, color=\"k\")\n",
    "    plt.xticks(range(0, len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom=-0.001, top=0.02)\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.legend([Line2D ([0], [0], color=\"c\", lw=4),\n",
    "                Line2D ([0], [0], color=\"b\", lw=4),\n",
    "                Line2D ([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "    plt.savefig('gradient.png', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "9b285a9ba3d544618baf476d6b03a171",
      "ffa808d8bc04498ca24a2030f8f5309a",
      "f3d38560348145d49262c0085578d637",
      "adc9b4ca642b4d3888501984e2eae60b",
      "27550cb8dde74363ad9cb032d24030ea",
      "7eded93b134746fabbac42e2fd1d07d2",
      "d4516f08803141b4bf10a3f8be134994",
      "efc3f992949c441a85d00fb0bbe66570"
     ]
    },
    "colab_type": "code",
    "id": "CngjX_mkAKXz",
    "outputId": "1ba8baf7-eec8-4dd6-9f30-73f4e86f1245"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:12: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70978822762f4facad8f7aa6b15f5162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:28: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "ALMOST ALL STUDENTS WHO ARE ACCEPTED INTO MEDICAL SCHOOLS OBTAIN A MEDICAL DEGREE \n",
      "ALMOST ALL STUDENTS WHO ARE ACCEPTED INTO MEDICAL SCHOOLS OBTAIN A MEDICAL DEGREE \n",
      "======\n",
      "0.3144131600856781\n",
      "0.34172675013542175\n",
      "0.36042365431785583\n",
      "0.31770119071006775\n",
      "0.23715148866176605\n",
      "0.37366628646850586\n",
      "0.3135872483253479\n",
      "0.2504916191101074\n",
      "0.28825119137763977\n",
      "0.32774338126182556\n",
      "0.2699856162071228\n",
      "0.3087587356567383\n",
      "0.3003072738647461\n",
      "0.25621938705444336\n",
      "0.23564964532852173\n",
      "0.34931278228759766\n",
      "0.24299149215221405\n",
      "0.2870831787586212\n",
      "0.3042893707752228\n",
      "0.3216700553894043\n",
      "0.31491464376449585\n",
      "0.26117753982543945\n",
      "0.2773367166519165\n",
      "0.23107270896434784\n",
      "0.30117085576057434\n",
      "0.24976834654808044\n",
      "0.269864022731781\n",
      "0.28853997588157654\n",
      "0.31672102212905884\n",
      "0.24410520493984222\n",
      "0.26866576075553894\n",
      "0.32528823614120483\n",
      "0.3760913014411926\n",
      "0.24864813685417175\n",
      "0.2566514313220978\n",
      "0.40447914600372314\n",
      "0.252943754196167\n",
      "0.2764131426811218\n",
      "0.4487375319004059\n",
      "0.2985667288303375\n",
      "0.26057925820350647\n",
      "0.2723957896232605\n",
      "0.31345421075820923\n",
      "0.24163062870502472\n",
      "0.34180963039398193\n",
      "0.2732292115688324\n",
      "0.25334808230400085\n",
      "0.357386976480484\n",
      "0.359447717666626\n",
      "0.24791955947875977\n",
      "=====\n",
      "THE POPULATION LIVES BY HERDING GOATS AND SHEEP OR BY TRADING \n",
      "THE POPULATION LIVES BY HERDING GOATS AND SHEEP OR BY TRADING \n",
      "======\n",
      "0.34878265857696533\n",
      "0.26537978649139404\n",
      "0.2940826416015625\n",
      "0.32953688502311707\n",
      "0.2455780953168869\n",
      "0.2663538157939911\n",
      "0.34775757789611816\n",
      "0.27011924982070923\n",
      "0.3285619914531708\n",
      "0.3046005666255951\n",
      "0.27093833684921265\n",
      "0.3946954011917114\n",
      "0.3062628209590912\n",
      "0.26837822794914246\n",
      "0.2739524841308594\n",
      "0.3905580937862396\n",
      "0.39035266637802124\n",
      "0.34996798634529114\n",
      "0.2573589086532593\n",
      "0.23580265045166016\n",
      "0.30915382504463196\n",
      "0.24155505001544952\n",
      "0.3301980793476105\n",
      "0.37350180745124817\n",
      "0.27588459849357605\n",
      "0.26225095987319946\n",
      "0.27917319536209106\n",
      "0.33371344208717346\n",
      "0.199669748544693\n",
      "0.368240624666214\n",
      "0.22970223426818848\n",
      "0.35803723335266113\n",
      "0.27092376351356506\n",
      "0.25440338253974915\n",
      "0.31147459149360657\n",
      "0.30396613478660583\n",
      "0.4616943895816803\n",
      "0.2862182855606079\n",
      "0.26464203000068665\n",
      "0.33474406599998474\n",
      "0.37069398164749146\n",
      "0.27193668484687805\n",
      "0.3095237612724304\n",
      "0.25407999753952026\n",
      "0.2678019106388092\n",
      "0.3050583004951477\n",
      "0.3098245859146118\n",
      "0.295329213142395\n",
      "0.41046416759490967\n",
      "0.24895595014095306\n",
      "=====\n",
      "AN IRANIAN FRIGATE BLOCKED AN ITALIAN WARSHIP IN THE PERSIAN GULF COMMA BUT MOVED AFTER GUN SIGHTS WERE LOCKED ONTO IT PERIOD \n",
      "AN RRANDAN FRRGGTE BLOCKED AN ATIIINN WORSHIP ON THE PERSENT GULF COMMA TUT MOVE  GUTER GUNSSITESH WERL LOCKED ON T WITPERIOD \n",
      "======\n",
      "0.316592812538147\n",
      "0.2486013025045395\n",
      "0.2705540359020233\n",
      "0.30324769020080566\n",
      "0.28358012437820435\n",
      "0.351743221282959\n",
      "0.34157076478004456\n",
      "0.31483194231987\n",
      "0.29522013664245605\n",
      "0.28471943736076355\n",
      "0.34046420454978943\n",
      "0.27739235758781433\n",
      "0.38380706310272217\n",
      "0.3538414537906647\n",
      "0.3294137120246887\n",
      "0.3286954164505005\n",
      "0.31423380970954895\n",
      "0.3392350971698761\n",
      "0.2734442949295044\n",
      "0.25712525844573975\n",
      "0.3000088632106781\n",
      "0.3718346953392029\n",
      "0.2983092963695526\n",
      "0.3124791979789734\n",
      "0.2406989485025406\n",
      "0.28052517771720886\n",
      "0.28083547949790955\n",
      "0.31932756304740906\n",
      "0.2925257086753845\n",
      "0.3119826018810272\n",
      "0.4040393531322479\n",
      "0.2996043860912323\n",
      "0.28063029050827026\n",
      "0.30823180079460144\n",
      "0.39747512340545654\n",
      "0.3861582279205322\n",
      "0.3748302161693573\n",
      "0.3522683084011078\n",
      "0.43547743558883667\n",
      "0.32268795371055603\n",
      "0.29686909914016724\n",
      "0.28985247015953064\n",
      "0.322864294052124\n",
      "0.41301649808883667\n",
      "0.3189055025577545\n",
      "0.27247941493988037\n",
      "0.3827260434627533\n",
      "0.3346675634384155\n",
      "0.4207136929035187\n",
      "0.3395550549030304\n",
      "=====\n",
      "BUT JUNK BONDS DASH THOSE ISSUED BY COMPANIES WITH LOW CREDIT RATINGS OR NONE AT ALL DASH FAILED TO JOIN IN THE RALLY PERIOD \n",
      "BUT JUNK BONDS DASH THOSE ISSUED BY COMPANIES WITH LOW CREDIT RATINGS ON NOTEROL LLL DASH FAILED TO JOIN IN THE RALLY PERIOD \n",
      "======\n",
      "0.3568588197231293\n",
      "0.2562238574028015\n",
      "0.2896900177001953\n",
      "0.3033950924873352\n",
      "0.3139544725418091\n",
      "0.30088964104652405\n",
      "0.3558046221733093\n",
      "0.29527562856674194\n",
      "0.25667205452919006\n",
      "0.31670141220092773\n",
      "0.3226546049118042\n",
      "0.3171004354953766\n",
      "0.2868616580963135\n",
      "0.3296252191066742\n",
      "0.2974182069301605\n",
      "0.28841859102249146\n",
      "0.30327290296554565\n",
      "0.2317630499601364\n",
      "0.3079775273799896\n",
      "0.2989254891872406\n",
      "0.26309633255004883\n",
      "0.2863790988922119\n",
      "0.2896692454814911\n",
      "0.3364278972148895\n",
      "0.24932055175304413\n",
      "0.2744998335838318\n",
      "0.28905320167541504\n",
      "0.3851020336151123\n",
      "0.4047218859195709\n",
      "0.3285441994667053\n",
      "0.27467331290245056\n",
      "0.2831723392009735\n",
      "0.22568681836128235\n",
      "0.30754148960113525\n",
      "0.44046494364738464\n",
      "0.290063738822937\n",
      "0.2522278130054474\n",
      "0.27593234181404114\n",
      "0.24289576709270477\n",
      "0.377402126789093\n",
      "0.3178260326385498\n",
      "0.35000723600387573\n",
      "0.27545198798179626\n",
      "0.39588478207588196\n",
      "0.32784953713417053\n",
      "0.2958323359489441\n",
      "0.3119605481624603\n",
      "0.29058530926704407\n",
      "0.3035002052783966\n",
      "0.27621161937713623\n",
      "=====\n",
      "HE NEVER OBTAINED A SECURE ACADEMIC POSITION OR PERMANENT EMPLOYMENT \n",
      "HE NEVER OBTAINED A SECURA ACADERIC POSITION OR PERMANENT EMPLOYMENT \n",
      "======\n",
      "0.26700109243392944\n",
      "0.3319542706012726\n",
      "0.43821981549263\n",
      "0.25853973627090454\n",
      "0.28865697979927063\n",
      "0.2892959713935852\n",
      "0.2712673544883728\n",
      "0.3289864659309387\n",
      "0.27387866377830505\n",
      "0.2871035933494568\n",
      "0.33288872241973877\n",
      "0.2284001260995865\n",
      "0.40986835956573486\n",
      "0.39826205372810364\n",
      "0.3740074038505554\n",
      "0.2730760872364044\n",
      "0.2793683707714081\n",
      "0.3758664131164551\n",
      "0.30554279685020447\n",
      "0.4768975079059601\n",
      "0.3273334801197052\n",
      "0.308011531829834\n",
      "0.4489864408969879\n",
      "0.3415352702140808\n",
      "0.26225122809410095\n",
      "0.3499909043312073\n",
      "0.31366726756095886\n",
      "0.2741512060165405\n",
      "0.2451431304216385\n",
      "0.312225878238678\n",
      "0.29859837889671326\n",
      "0.2947879135608673\n",
      "0.2389584481716156\n",
      "0.29539433121681213\n",
      "0.4394088089466095\n",
      "0.2626647353172302\n",
      "0.22006677091121674\n",
      "0.30946850776672363\n",
      "0.3027624785900116\n",
      "0.3652604818344116\n",
      "0.28528186678886414\n",
      "0.3007492423057556\n",
      "0.2984543442726135\n",
      "0.28010064363479614\n",
      "0.28517428040504456\n",
      "0.2672574520111084\n",
      "0.3089110851287842\n",
      "0.3065721392631531\n",
      "0.2710241377353668\n",
      "0.2853545546531677\n",
      "=====\n",
      "THE COMPANY OPERATES ABOUT TWENTY FIVE STORES COMMA MOST OF THEM IN CALIFORNIA PERIOD \n",
      "THE COMPANY OPERATES ABOUT TWENTY FIVE STORES COMMA MOST OF THEM IN CALIFORNIA PERIOD \n",
      "======\n",
      "0.3554479479789734\n",
      "0.387279748916626\n",
      "0.29882240295410156\n",
      "0.3723903000354767\n",
      "0.4179622530937195\n",
      "0.39088818430900574\n",
      "0.3017742335796356\n",
      "0.3474244475364685\n",
      "0.2656137943267822\n",
      "0.3132701516151428\n",
      "0.3321082592010498\n",
      "0.24072085320949554\n",
      "0.3164362609386444\n",
      "0.29572632908821106\n",
      "0.3406490087509155\n",
      "0.28663286566734314\n",
      "0.25911539793014526\n",
      "0.333204448223114\n",
      "0.37230396270751953\n",
      "0.3044937252998352\n",
      "0.32745811343193054\n",
      "0.2684536576271057\n",
      "0.2877635955810547\n",
      "0.26033613085746765\n",
      "0.30393680930137634\n",
      "0.2730715870857239\n",
      "0.2899461090564728\n",
      "0.37469133734703064\n",
      "0.35313522815704346\n",
      "0.2589660584926605\n",
      "0.32349154353141785\n",
      "0.394825279712677\n",
      "0.32508939504623413\n",
      "0.36115562915802\n",
      "0.28365108370780945\n",
      "0.2727559208869934\n",
      "0.295695960521698\n",
      "0.2724018394947052\n",
      "0.3316945433616638\n",
      "0.3002014458179474\n",
      "0.3981057107448578\n",
      "0.2430797666311264\n",
      "0.3049146234989166\n",
      "0.2638919949531555\n",
      "0.3979215919971466\n",
      "0.36732909083366394\n",
      "0.3446483910083771\n",
      "0.3432456851005554\n",
      "0.2173645794391632\n",
      "0.266357958316803\n",
      "=====\n",
      "MR. CHEN WAS CONSIDERING USING LASERS RATHER THAN WIRES IN THAT MACHINE PERIOD \n",
      "MR. CHEN WAS CONSIDERING USING LASERS RATHER AHAN WAYER IN THAT MACHINE PERIOD \n",
      "======\n",
      "0.3394417464733124\n",
      "0.2827768623828888\n",
      "0.26322898268699646\n",
      "0.3448425829410553\n",
      "0.321964293718338\n",
      "0.2517627477645874\n",
      "0.2494800090789795\n",
      "0.3069695234298706\n",
      "0.3307439684867859\n",
      "0.2610340118408203\n",
      "0.24529848992824554\n",
      "0.33779504895210266\n",
      "0.2308085560798645\n",
      "0.3688734173774719\n",
      "0.26169562339782715\n",
      "0.2734667956829071\n",
      "0.3024018704891205\n",
      "0.2968970239162445\n",
      "0.4395437240600586\n",
      "0.42572271823883057\n",
      "0.39479753375053406\n",
      "0.3413364291191101\n",
      "0.3387332856655121\n",
      "0.35042548179626465\n",
      "0.2941017746925354\n",
      "0.2604235112667084\n",
      "0.29749739170074463\n",
      "0.3425646722316742\n",
      "0.27646878361701965\n",
      "0.32526957988739014\n",
      "0.39052456617355347\n",
      "0.27259132266044617\n",
      "0.2376558929681778\n",
      "0.276630699634552\n",
      "0.28147801756858826\n",
      "0.2946268916130066\n",
      "0.21639499068260193\n",
      "0.26821964979171753\n",
      "0.3888084292411804\n",
      "0.29660215973854065\n",
      "0.23264247179031372\n",
      "0.23270028829574585\n",
      "0.3236550986766815\n",
      "0.25145259499549866\n",
      "0.3059430718421936\n",
      "0.3868361711502075\n",
      "0.2649649977684021\n",
      "0.39007648825645447\n",
      "0.2712172865867615\n",
      "0.40759095549583435\n",
      "=====\n",
      "DOUBLE-QUOTE HE'S A WEAK GUY COMMA DOUBLE-QUOTE SAYS MR. ROSE COMMA THE POLITICAL CONSULTANT COMMA DOUBLE-QUOTE SUBJECT TO A LOT OF PRESSURE AND OBVIOUSLY NOT A CRUSADER PERIOD DOUBLE-QUOTE \n",
      "DOUBLE-QUOTE HE'S A WEEK GUY COMMA DOUBLE-QUOTE SAYS MR. ROLE COMMA THE POLITICAL CONSULTANT COMMA DOUBLE-QUOTE SUBJECT TO A LOT OF PRESSURE AND OBVIOUSLE NOT A CRECEDER PERIOD DOUBLE-QUOTE \n",
      "======\n",
      "0.3732123374938965\n",
      "0.42989760637283325\n",
      "0.3853400945663452\n",
      "0.3894333839416504\n",
      "0.35021477937698364\n",
      "0.5070037841796875\n",
      "0.346606969833374\n",
      "0.3023615777492523\n",
      "0.24008071422576904\n",
      "0.3748130202293396\n",
      "0.3252832889556885\n",
      "0.3249194324016571\n",
      "0.31473806500434875\n",
      "0.34335097670555115\n",
      "0.2882899343967438\n",
      "0.3230973780155182\n",
      "0.32220256328582764\n",
      "0.3488401174545288\n",
      "0.2887473702430725\n",
      "0.28253641724586487\n",
      "0.3685533404350281\n",
      "0.2842555046081543\n",
      "0.34841978549957275\n",
      "0.355436235666275\n",
      "0.39664608240127563\n",
      "0.29829666018486023\n",
      "0.23167775571346283\n",
      "0.2914106249809265\n",
      "0.3446637988090515\n",
      "0.3886820375919342\n",
      "0.31555959582328796\n",
      "0.28818318247795105\n",
      "0.2603015601634979\n",
      "0.32747912406921387\n",
      "0.2957811653614044\n",
      "0.37329453229904175\n",
      "0.33698713779449463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ipykernel/__main__.py:55: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95e34b478d941eba458ca7ef0141830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1043, 64, 40])\n",
      "=====\n",
      "PAINEWEBBER WAS ONE OF THE EARLY WALL STREET FIRMS TO GET INTO VENTURE CAPITAL \n",
      "PAIN WEBERER WAS ONE OF THE EARLY WALL STREET FIRMS TO GET INTEVENTURE CAPITI PIPINE \n",
      "======\n",
      "torch.Size([1237, 64, 40])\n",
      "=====\n",
      "MUCH OF THE GROUND BEEF CONSUMED IN THE UNITED STATES COMES FROM DAIRY COWS \n",
      "MUCH OF THE GROUND BEEF CONSUMED THIL THE UNITED STATES COMES FROM DAIRY COWS \n",
      "======\n",
      "torch.Size([1335, 64, 40])\n",
      "=====\n",
      "FOR INVESTORS WILLING TO TAKE MORE RISK COMMA THE NEARBY CONTRACT MONTH COMMA WHICH TRADED WITHOUT PRICE LIMITS COMMA WAS ONE ALTERNATIVE PERIOD \n",
      "FOR INVESTORS LINE TO TAKE MORE RISE COMMA THE NEAR BY CONTRACT MONTH COMMA WHICH TRADE WITH OUT PRISELY ITS COMMA WITH WALL TERNATIVE PERIOD \n",
      "======\n",
      "torch.Size([1166, 64, 40])\n",
      "=====\n",
      "IN ONE SENSE THE U. S. ADMINISTRATION'S SUPPORT OF THE MEXICAN PLAN ISOLATES BANKAMERICA AND MANUFACTURERS HANOVER \n",
      "IN ONE CENTS THE USEMED MINISTRATION SUPPORT OF THE NEXT CONPLAN I  Y LATES BANK AMERICA MANUFACTORS AND OVER \n",
      "======\n",
      "torch.Size([1179, 64, 40])\n",
      "=====\n",
      "THE ENORMOUS AMOUNTS OF CARBON DIOXIDE IN THE ATMOSPHERE CAUSE THIS HIGH PRESSURE \n",
      "THE ENORMOUS THE MOUNTS OF CARBOD D AXIDE IN THE ATMOSPHERE CAUSE THIS HIGH PRESSION \n",
      "======\n",
      "torch.Size([1350, 64, 40])\n",
      "=====\n",
      "AFTER THE I. B. M. PERSONAL COMPUTER CAME OUT IN NINETEEN EIGHTY TWO COMMA MESSRS. PERIOD \n",
      "AFTER THE AD BIEM PERSONAL COMPUTER CAMALI NINETEEN EIGHTY TWO COMMA MASSERS PERIOD \n",
      "======\n",
      "torch.Size([1579, 64, 40])\n",
      "=====\n",
      "THE STATUE OF LIBERTY AND ELLIS ISLAND ARE WITHIN THE NEW JERSEY WATERS OF NEW YORK BAY \n",
      "THE STATUE OF LIBERTY CHM A HOLLS ISLAND ARE WITHID AN THIN TENERE JERSEY WARDERS OF NEW YORK BAY \n",
      "======\n",
      "torch.Size([1743, 64, 40])\n",
      "=====\n",
      "HE SAID MORTON THIOKOL HAS ENOUGH AMMONIUM PERCHLORATE FOR THREE SHUTTLE MISSIONS PERIOD \n",
      "HE SAID WARGAN IN FICK COLE HAS ENOUGH OR MONEY UM PERCLORIA FOUR THREE SHATTLEMITIONS PERIOD \n",
      "======\n",
      "torch.Size([1447, 64, 40])\n",
      "=====\n",
      "THE RECENT ABUSES ON WALL STREET HAVE MADE IT A POSSIBLE TARGET FOR A NECESSARY TAX INCREASE \n",
      "THE RECENT BUSUSES ON WALL STREET ABMATED A PROSSIBLE CARGET FOR AN NECESSARY TAX INCREASE \n",
      "======\n",
      "torch.Size([1439, 64, 40])\n",
      "=====\n",
      "A SPOKESMAN FOR THE G. M. GROUP SAID THE REDEVELOPMENT IS CONTINGENT ON RECEIVING CERTAIN TAX ABATEMENTS FROM THE CITY AND STATE PERIOD \n",
      "A SPOKESMAN FOR THE G. M. GROUPS AT THE RE DEVELOPMENT IS CONTINGINE ON MORE SEEMING CERTAIN TAX ABMATEMENTS FROM THE CITY AND STATE PERIOD \n",
      "======\n",
      "torch.Size([1333, 64, 40])\n",
      "=====\n",
      "ALL THE BONDS WILL BE DATED NEXT MONDAY \n",
      "ALL THE BONDS WILL BE DATED NEXT MONDAY \n",
      "======\n",
      "torch.Size([1237, 64, 40])\n",
      "=====\n",
      "BOTH PETROLEUM AND NATURAL GAS DEPOSITS ARE SCATTERED THROUGH EASTERN OHIO \n",
      "BOTH PETROLEUM AND NATURAL GAS DEPOSINES S ARE SCATTERED THROUGH EASTERN OHIO \n",
      "======\n",
      "torch.Size([1236, 64, 40])\n",
      "=====\n",
      "THE THRIFT BAILOUT BILL WAS SENT TO BUSH WHO IS EXPECTED TO SIGN IT AS SOON AS WEDNESDAY \n",
      "THE FIRFT BAIL UT BUILL WITH WHO WIS EXPECTED TO SUN IT IS WEDNESDAY \n",
      "======\n",
      "torch.Size([1567, 64, 40])\n",
      "=====\n",
      "MUCH OF THE GROUND BEEF CONSUMED IN THE UNITED STATES COMES FROM DAIRY COWS \n",
      "MUCH OF THE GROUND BEES CONSUMED IN THE OUTS DATES COMES FROM DAIRY COUNTS \n",
      "======\n",
      "torch.Size([1376, 64, 40])\n",
      "=====\n",
      "THE ACTION REPRESENTED A TOUGHER STANCE AGAINST FINANCIAL INSTITUTIONS PERIOD \n",
      "THE ACTION REBRESENTED A TUUIFER STANCE AGGEST FINANCIAL IS TITATIONS PERIOD \n",
      "======\n",
      "torch.Size([1443, 64, 40])\n",
      "=====\n",
      "ALMOST ALL STUDENTS WHO ARE ACCEPTED INTO MEDICAL SCHOOLS OBTAIN A MEDICAL DEGREE \n",
      "ALMOST ALL STUDENTS WHO ARE ACCEPTED INTO MEDICAL SCHOOLS OBTAIN A MEDICAL DEGREE \n",
      "======\n",
      "torch.Size([1153, 64, 40])\n",
      "=====\n",
      "DOCTOR PIERCE SAID READERS OF PHILIP MORRIS'S MAGAZINE PROBABLY ARE BETTER EDUCATED THAN THE TYPICAL SMOKER PERIOD \n",
      "DOCTOR PEAR SAID READERS A FELL PMERISES MAGAZINE PROBABLY ARE BETTER EDUCATED IN THE TYPICAATED THAN THE TIPICAL SMOKER PERIOD \n",
      "======\n",
      "torch.Size([1080, 18, 40])\n",
      "=====\n",
      "DOUBLE-QUOTE HAVEN'T WE ALREADY GONE OVERBOARD IN S. B. A. BUDGET CUTS QUESTION-MARK DOUBLE-QUOTE \n",
      "DOUBLE-QUOTE HAVEN'T LEARITY DON OVER BOARD IN ASKED BE ABBUDGET CATS QUESTION-MARK DOUBLE-QUOTE \n",
      "======\n",
      "\n",
      "epoch 1: train loss : 0.3117, train perplexity : 1.1821, valid loss : 4.3792, valid perplexity: 110.22 valid distance : 13.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507d9edf182145d4b803d42e1c9c0eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "DOUBLE-QUOTE THERE IS AN ATMOSPHERE OF DISTRUST THROUGHOUT THE MINISTRY COMMA DOUBLE-QUOTE SAYS MR. MIRANDA COMMA WHO NOW GIVES FRENCH LESSONS HERE PERIOD \n",
      "DOUBLE-QUOTE THERE IS AN ATMOSPHERE DISDISTRUST THROUGHOUT THE MINISTRY COMMA DOUBLE-QUOTE SAYS MR. MARRNDA COMMA WHO DOW GISE  FRENCH LUSI  ' HERE <eos>ERIOD \n",
      "======\n",
      "0.33252885937690735\n",
      "0.2841033339500427\n",
      "0.24754643440246582\n",
      "0.24213308095932007\n",
      "0.2609356641769409\n",
      "0.27128729224205017\n",
      "0.3056928813457489\n",
      "0.3985348641872406\n",
      "0.3035445511341095\n",
      "0.30865392088890076\n",
      "0.2793140113353729\n",
      "0.29716628789901733\n",
      "0.36483484506607056\n",
      "0.2196824550628662\n",
      "0.2812917232513428\n",
      "0.29388052225112915\n",
      "0.23191846907138824\n",
      "0.26346611976623535\n",
      "0.28213033080101013\n",
      "0.27604940533638\n",
      "0.23919489979743958\n",
      "0.3168918192386627\n",
      "0.20282702147960663\n",
      "0.37879812717437744\n",
      "0.25047624111175537\n",
      "0.23071548342704773\n",
      "0.18166100978851318\n",
      "0.24045626819133759\n",
      "0.22723908722400665\n",
      "0.24340033531188965\n",
      "0.2901761531829834\n",
      "0.23248420655727386\n",
      "0.2524130642414093\n",
      "0.26299047470092773\n",
      "0.22139909863471985\n",
      "0.28783971071243286\n",
      "0.23920419812202454\n",
      "0.29685884714126587\n",
      "0.2235250025987625\n",
      "0.2769395112991333\n",
      "0.36011040210723877\n",
      "0.35182344913482666\n",
      "0.24202701449394226\n",
      "0.26130548119544983\n",
      "0.20752783119678497\n",
      "0.2296970635652542\n",
      "0.2277776002883911\n",
      "0.2112511545419693\n",
      "0.21968300640583038\n",
      "0.25873422622680664\n",
      "=====\n",
      "THE PERCENTAGE CHANGE IS SINCE YEAR HYPHEN END PERIOD \n",
      "THE PERCENT GE CHANGE BS SINCE YEAR HYPHEN END PERIOD \n",
      "======\n",
      "0.24186712503433228\n",
      "0.19491823017597198\n",
      "0.22259297966957092\n",
      "0.22756467759609222\n",
      "0.2648772597312927\n",
      "0.27918681502342224\n",
      "0.26242852210998535\n",
      "0.2610566020011902\n",
      "0.2189323902130127\n",
      "0.20573358237743378\n",
      "0.23834402859210968\n",
      "0.28718292713165283\n",
      "0.2670140266418457\n",
      "0.27142083644866943\n",
      "0.2536524832248688\n",
      "0.21903091669082642\n",
      "0.18796218931674957\n",
      "0.2669011652469635\n",
      "0.28463178873062134\n",
      "0.2743450403213501\n",
      "0.28755107522010803\n",
      "0.23827378451824188\n",
      "0.2875823974609375\n",
      "0.2389252483844757\n",
      "0.2081318348646164\n",
      "0.18847160041332245\n",
      "0.28395769000053406\n",
      "0.23132500052452087\n",
      "0.1820237785577774\n",
      "0.24423931539058685\n",
      "0.27301087975502014\n",
      "0.1782638281583786\n",
      "0.2478172481060028\n",
      "0.2515660226345062\n",
      "0.2275819033384323\n",
      "0.358413964509964\n",
      "0.225458562374115\n",
      "0.29609400033950806\n",
      "0.2265390157699585\n",
      "0.20900483429431915\n",
      "0.2090325802564621\n",
      "0.33370232582092285\n",
      "0.2659923732280731\n",
      "0.3415413200855255\n",
      "0.2369842380285263\n",
      "0.308287650346756\n",
      "0.22278165817260742\n",
      "0.2434559166431427\n",
      "0.39066651463508606\n",
      "0.2997676134109497\n",
      "=====\n",
      "SOME TOURIST AGENCIES ALSO ARRANGE PHONY GROUP TOURS AND SELL THE DISCOUNT TICKETS TO INDIVIDUAL TRAVELERS \n",
      "SOME TEURSTT AGENCIES ALSO ARAANGE PHONY GROUP TOORS AND SELL THE DISCOUNT TICKETS TO INDIVIDUAL TRAVELERS \n",
      "======\n",
      "0.2331751137971878\n",
      "0.2114194631576538\n",
      "0.2681938111782074\n",
      "0.27887171506881714\n",
      "0.25754836201667786\n",
      "0.2361021488904953\n",
      "0.23838596045970917\n",
      "0.28427445888519287\n",
      "0.22423341870307922\n",
      "0.24313905835151672\n",
      "0.2588156759738922\n",
      "0.2598080039024353\n",
      "0.24058358371257782\n",
      "0.2348889261484146\n",
      "0.29805219173431396\n",
      "0.24444542825222015\n",
      "0.2049407660961151\n",
      "0.2471500188112259\n",
      "0.2772040367126465\n",
      "0.21259167790412903\n",
      "0.2882167100906372\n",
      "0.2334708273410797\n",
      "0.2673671543598175\n",
      "0.30567654967308044\n",
      "0.2656874656677246\n",
      "0.3048754930496216\n",
      "0.2182912677526474\n",
      "0.25605979561805725\n",
      "0.2577630579471588\n",
      "0.28197211027145386\n",
      "0.3111562430858612\n",
      "0.3044840395450592\n",
      "0.22848111391067505\n",
      "0.30709677934646606\n",
      "0.3475331664085388\n",
      "0.2331022173166275\n",
      "0.31793326139450073\n",
      "0.3083897531032562\n",
      "0.2658873498439789\n",
      "0.294259250164032\n",
      "0.2636771500110626\n",
      "0.27668631076812744\n",
      "0.23666377365589142\n",
      "0.2584225535392761\n",
      "0.25362101197242737\n",
      "0.19722339510917664\n",
      "0.23405374586582184\n",
      "0.26573091745376587\n",
      "0.232573002576828\n",
      "0.3271510899066925\n",
      "=====\n",
      "IT IS IN THE FINANCIAL MARKETS THAT THE BATTLE OF THE DOLLAR WILL HAVE TO BE FOUGHT \n",
      "IT IT IN THE FINANCIAL MARKETS THAT THE BATTLE OF THE DOLLAR WILL HAVE TO BE FOUGHT \n",
      "======\n",
      "0.3411963880062103\n",
      "0.3183756470680237\n",
      "0.30371880531311035\n",
      "0.2596663534641266\n",
      "0.215140238404274\n",
      "0.28455445170402527\n",
      "0.2877976894378662\n",
      "0.36822086572647095\n",
      "0.26945197582244873\n",
      "0.3155527412891388\n",
      "0.2471870481967926\n",
      "0.2821425199508667\n",
      "0.35577622056007385\n",
      "0.2508662939071655\n",
      "0.22029782831668854\n",
      "0.2718294560909271\n",
      "0.3738139271736145\n",
      "0.26823413372039795\n",
      "0.2109617292881012\n",
      "0.28548434376716614\n",
      "0.30808982253074646\n",
      "0.2851259410381317\n",
      "0.18851333856582642\n",
      "0.36546799540519714\n",
      "0.2272421270608902\n",
      "0.24585281312465668\n",
      "0.35547617077827454\n",
      "0.2771102786064148\n",
      "0.3237746059894562\n",
      "0.1889699548482895\n",
      "0.39981532096862793\n",
      "0.2557809352874756\n",
      "0.25795161724090576\n",
      "0.2673056423664093\n",
      "0.2114371359348297\n",
      "0.22949551045894623\n",
      "0.3276044726371765\n",
      "0.26104864478111267\n",
      "0.27986612915992737\n",
      "0.28324252367019653\n",
      "0.24966470897197723\n",
      "0.3587997257709503\n",
      "0.24049939215183258\n",
      "0.27158719301223755\n",
      "0.3329819440841675\n",
      "0.3008078634738922\n",
      "0.26796138286590576\n",
      "0.25023409724235535\n",
      "0.3045727610588074\n",
      "0.22309871017932892\n",
      "=====\n",
      "I WAS ENVIOUS OF MY TEAM'S SNATCHER A TALL SKINNY NURSE UNTIL I SAW WHAT SHE HAD TO ENDURE IN THE NAME OF ESPRIT DE CORPS \n",
      "WT HISS VIOUS OF MY TEAMS  SNATURER A TALL SKEIIY NURSE UNTILLY SAW WHIGHHEE HAD TO INDURE IN THE NAME OF TSPRED AC COUR  \n",
      "======\n",
      "0.24494148790836334\n",
      "0.2892480194568634\n",
      "0.2793629467487335\n",
      "0.30374786257743835\n",
      "0.3393697142601013\n",
      "0.2792447507381439\n",
      "0.2619245648384094\n",
      "0.26827993988990784\n",
      "0.3076898753643036\n",
      "0.2347138226032257\n",
      "0.23041340708732605\n",
      "0.24045835435390472\n",
      "0.2573555111885071\n",
      "0.2739501893520355\n",
      "0.2780357897281647\n",
      "0.2520444691181183\n",
      "0.29901817440986633\n",
      "0.30555540323257446\n",
      "0.33871424198150635\n",
      "0.26532086730003357\n",
      "0.2560942471027374\n",
      "0.30728980898857117\n",
      "0.30233725905418396\n",
      "0.21241888403892517\n",
      "0.28160223364830017\n",
      "0.34734877943992615\n",
      "0.2734319865703583\n",
      "0.3024885356426239\n",
      "0.31408917903900146\n",
      "0.2792288661003113\n",
      "0.22719748318195343\n",
      "0.26527348160743713\n",
      "0.22393633425235748\n",
      "0.23856256902217865\n",
      "0.26973313093185425\n",
      "0.28157031536102295\n",
      "0.2681557238101959\n",
      "0.31318187713623047\n",
      "0.3341676592826843\n",
      "0.2233758419752121\n",
      "0.2700161337852478\n",
      "0.2935936748981476\n",
      "0.26205921173095703\n",
      "0.3092077076435089\n",
      "0.22820745408535004\n",
      "0.22011196613311768\n",
      "0.2986134886741638\n",
      "0.268496036529541\n",
      "0.36664843559265137\n",
      "0.2745448052883148\n",
      "=====\n",
      "PHILOSOPHERS OF EDUCATION OFTEN DIFFER IN THEIR VIEWS ON THE NATURE OF KNOWLEDGE \n",
      "PHILOSOPHERS OF EDUCATION OFTEN DIFFER IN THEIR VIEWS ON THE NATURE OF KNOWLEDGE \n",
      "======\n",
      "0.26158466935157776\n",
      "0.19890196621418\n",
      "0.3034510612487793\n",
      "0.30802664160728455\n",
      "0.26071056723594666\n",
      "0.2685539424419403\n",
      "0.31750038266181946\n",
      "0.26332131028175354\n",
      "0.2722937762737274\n",
      "0.29765838384628296\n",
      "0.27348053455352783\n",
      "0.2507559061050415\n",
      "0.2517598867416382\n",
      "0.2699829339981079\n",
      "0.28313833475112915\n",
      "0.2939126193523407\n",
      "0.2226981818675995\n",
      "0.24584676325321198\n",
      "0.30886605381965637\n",
      "0.2638757824897766\n",
      "0.22065085172653198\n",
      "0.24970267713069916\n",
      "0.2882809340953827\n",
      "0.23355160653591156\n",
      "0.3531840741634369\n",
      "0.2589656710624695\n",
      "0.27186116576194763\n",
      "0.2518947720527649\n",
      "0.32625117897987366\n",
      "0.29596132040023804\n",
      "0.2553827464580536\n",
      "0.35512980818748474\n",
      "0.23386508226394653\n",
      "0.2835766673088074\n",
      "0.3168540894985199\n",
      "0.2506273686885834\n",
      "0.32389527559280396\n",
      "0.29297927021980286\n",
      "0.262122243642807\n",
      "0.2717576026916504\n",
      "0.25842565298080444\n",
      "0.24063073098659515\n",
      "0.26586657762527466\n",
      "0.23117214441299438\n",
      "0.28279346227645874\n",
      "0.2843305468559265\n",
      "0.2763935625553131\n",
      "0.2505176067352295\n",
      "0.3545432388782501\n",
      "0.27398666739463806\n",
      "=====\n",
      "SEPARATELY BRITAIN'S DEPARTMENT OF ENERGY ISSUED A LETTER YESTERDAY TO ALL COMPANIES OPERATING IN THE U. K. SECTOR OF THE NORTH SEA SUGGESTING MEASURES TO ENHANCE SAFETY \n",
      "SEPARATELY BRITAIN'S DEPARTMENT OF ENERGY ISSUED A LETTER YESTERDAY TO ALL COMPANYES OPERATING IN THE U. K. SECTOR OF THE NORTHYS. SUGGGESTING MEASURES TO ANHANCE SAFETY \n",
      "======\n",
      "0.2804931402206421\n",
      "0.3118920624256134\n",
      "0.24755437672138214\n",
      "0.23658162355422974\n",
      "0.26979348063468933\n",
      "0.2709755003452301\n",
      "0.28812703490257263\n",
      "0.2080518752336502\n",
      "0.20078381896018982\n",
      "0.26531481742858887\n",
      "0.2793351411819458\n",
      "0.23717531561851501\n",
      "0.3053913116455078\n",
      "0.23945027589797974\n",
      "0.29127219319343567\n",
      "0.4024294316768646\n",
      "0.2737714946269989\n",
      "0.28968384861946106\n",
      "0.2552303969860077\n",
      "0.2744128108024597\n",
      "0.2508876621723175\n",
      "0.443638414144516\n",
      "0.22135956585407257\n",
      "0.25260916352272034\n",
      "0.23292773962020874\n",
      "0.25066420435905457\n",
      "0.3943737745285034\n",
      "0.26311373710632324\n",
      "0.2957015335559845\n",
      "0.23145563900470734\n",
      "0.24598859250545502\n",
      "0.31820541620254517\n",
      "0.31465163826942444\n",
      "0.24381716549396515\n",
      "0.29774191975593567\n",
      "0.3156134784221649\n",
      "0.2884479761123657\n",
      "0.2002650946378708\n",
      "0.261218398809433\n",
      "0.2749911844730377\n",
      "0.3011522889137268\n",
      "0.2246830016374588\n",
      "0.25058451294898987\n",
      "0.273505836725235\n",
      "0.2786282002925873\n",
      "0.2649509608745575\n",
      "0.2521309554576874\n",
      "0.2547217905521393\n",
      "0.27679499983787537\n",
      "0.26330333948135376\n",
      "=====\n",
      "THE FORTY TWO YEAR OLD MR. WILLIS WILL SUCCEED EARLE W. PITT SIXTY FOUR \n",
      "THE FORTY TWO YEAR OLD MR. WILLIS WILL SUCCEED EARLE W. PITT SIXTY FOUR \n",
      "======\n",
      "0.25148314237594604\n",
      "0.23805560171604156\n",
      "0.2726370096206665\n",
      "0.3144983649253845\n",
      "0.2699779272079468\n",
      "0.28411850333213806\n",
      "0.3074750602245331\n",
      "0.36354270577430725\n",
      "0.2764996886253357\n",
      "0.2645917236804962\n",
      "0.23409919440746307\n",
      "0.3183270990848541\n",
      "0.2687620520591736\n",
      "0.23043569922447205\n",
      "0.22962968051433563\n",
      "0.29683205485343933\n",
      "0.2711959779262543\n",
      "0.24043913185596466\n",
      "0.2678118944168091\n",
      "0.26821616291999817\n",
      "0.2873283624649048\n",
      "0.2724299132823944\n",
      "0.30822205543518066\n",
      "0.2972652316093445\n",
      "0.2975514531135559\n",
      "0.2577885091304779\n",
      "0.22922639548778534\n",
      "0.2596070468425751\n",
      "0.2696521282196045\n",
      "0.2574267089366913\n",
      "0.29700911045074463\n",
      "0.6606009602546692\n",
      "0.27328330278396606\n",
      "0.2914416491985321\n",
      "0.24982979893684387\n",
      "0.3317062556743622\n",
      "0.2998370826244354\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baf19b3339e46dcb59ab52a85ab9ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1043, 64, 40])\n",
      "=====\n",
      "PAINEWEBBER WAS ONE OF THE EARLY WALL STREET FIRMS TO GET INTO VENTURE CAPITAL \n",
      "PAIN WEEBER WAS ONE OF THE EARLY WALL STREEN FIRMS TO GET INTERVENTURE CAPITA PAINT \n",
      "======\n",
      "torch.Size([1237, 64, 40])\n",
      "=====\n",
      "MUCH OF THE GROUND BEEF CONSUMED IN THE UNITED STATES COMES FROM DAIRY COWS \n",
      "MUCH OF THE GROUND BEEF CONSUMED TO THE UNITED STATES COMES FROM DAIRY COWS \n",
      "======\n",
      "torch.Size([1335, 64, 40])\n",
      "=====\n",
      "FOR INVESTORS WILLING TO TAKE MORE RISK COMMA THE NEARBY CONTRACT MONTH COMMA WHICH TRADED WITHOUT PRICE LIMITS COMMA WAS ONE ALTERNATIVE PERIOD \n",
      "FOR INVESTOR LINETO TAKE MORE RIS COMMA THE NEARBY CONTRACT MONTH COMMA WHICH TRADED WITH OUT PRISELYMITS COMMA WILL WALL TERTATED PERIOD \n",
      "======\n",
      "torch.Size([1166, 64, 40])\n",
      "=====\n",
      "IN ONE SENSE THE U. S. ADMINISTRATION'S SUPPORT OF THE MEXICAN PLAN ISOLATES BANKAMERICA AND MANUFACTURERS HANOVER \n",
      "IN ONE CENTS THE HAS BED MINISTRATION SUPPORT OF THE MEXT CONPLAN ISLATES BANKAMARIPA A MANUFACTORS AND OVER \n",
      "======\n",
      "torch.Size([1179, 64, 40])\n",
      "=====\n",
      "THE ENORMOUS AMOUNTS OF CARBON DIOXIDE IN THE ATMOSPHERE CAUSE THIS HIGH PRESSURE \n",
      "THE ENORMOUS AMOUNTS OF CARBON DIOXIDE IN THE ATMOSPARE CAUSE THIS HIGH PRESSICE \n",
      "======\n",
      "torch.Size([1350, 64, 40])\n",
      "=====\n",
      "AFTER THE I. B. M. PERSONAL COMPUTER CAME OUT IN NINETEEN EIGHTY TWO COMMA MESSRS. PERIOD \n",
      "AFTER THE A. BIM PERSONAL COMPUTER A. KAMO IN NINETEEN EIGHTY TWO COMMA MASSERS PERIOD \n",
      "======\n",
      "torch.Size([1579, 64, 40])\n",
      "=====\n",
      "THE STATUE OF LIBERTY AND ELLIS ISLAND ARE WITHIN THE NEW JERSEY WATERS OF NEW YORK BAY \n",
      "THE STATUE OF LIBERTY CHM A POLIS ISLAND ARE WITHIN THE NEW JERSEY WARDERS OF NEW YORK BAY \n",
      "======\n",
      "torch.Size([1743, 64, 40])\n",
      "=====\n",
      "HE SAID MORTON THIOKOL HAS ENOUGH AMMONIUM PERCHLORATE FOR THREE SHUTTLE MISSIONS PERIOD \n",
      "HE SAID WARTEN IT FIC COLL HAS NOUGH OMMONEY UMPER CLORIET FOURTH THREE SHATTLEMITIONS PERIOD \n",
      "======\n",
      "torch.Size([1447, 64, 40])\n",
      "=====\n",
      "THE RECENT ABUSES ON WALL STREET HAVE MADE IT A POSSIBLE TARGET FOR A NECESSARY TAX INCREASE \n",
      "THE RECENT ABUUSES ON WALL STRATE OF A POSSIBLE CARGET FOR AN NECESSARY TAX INCREASE \n",
      "======\n",
      "torch.Size([1439, 64, 40])\n",
      "=====\n",
      "A SPOKESMAN FOR THE G. M. GROUP SAID THE REDEVELOPMENT IS CONTINGENT ON RECEIVING CERTAIN TAX ABATEMENTS FROM THE CITY AND STATE PERIOD \n",
      "A SPOKESMAN FOR THE G. M. GROUPS AS THE REDDEVELOPMENT IS CONTINGENT ON ARE SEEVING CERTAIN TAX ABATEMENTS FROM THE CITY AND STATE PERIOD \n",
      "======\n",
      "torch.Size([1333, 64, 40])\n",
      "=====\n",
      "ALL THE BONDS WILL BE DATED NEXT MONDAY \n",
      "ALL THE BONDS WILL BE DATED NEXT MONDAY \n",
      "======\n",
      "torch.Size([1237, 64, 40])\n",
      "=====\n",
      "BOTH PETROLEUM AND NATURAL GAS DEPOSITS ARE SCATTERED THROUGH EASTERN OHIO \n",
      "BOTH PETROLEUM AND NATURAL GAS DEPOSITS S S S S S S S ATTRD THROUGH EASTERN OHIO \n",
      "======\n",
      "torch.Size([1236, 64, 40])\n",
      "=====\n",
      "THE THRIFT BAILOUT BILL WAS SENT TO BUSH WHO IS EXPECTED TO SIGN IT AS SOON AS WEDNESDAY \n",
      "THE THRIFT BAIL OUT BILL WITH SENT TO BUSH WHO IS EXPECTED TO SUN IT IS WINDSDAY \n",
      "======\n",
      "torch.Size([1567, 64, 40])\n",
      "=====\n",
      "MUCH OF THE GROUND BEEF CONSUMED IN THE UNITED STATES COMES FROM DAIRY COWS \n",
      "MUCH OF THE GROUND BEEF CONSUMED IN THE UNSTATES COMES FROM DAIRY COWNES \n",
      "======\n",
      "torch.Size([1376, 64, 40])\n",
      "=====\n",
      "THE ACTION REPRESENTED A TOUGHER STANCE AGAINST FINANCIAL INSTITUTIONS PERIOD \n",
      "THE ACTION REPRESENTED A TUULIFE STANCE AGAIST FINAL IS TITATIONS PERIOD \n",
      "======\n",
      "torch.Size([1443, 64, 40])\n",
      "=====\n",
      "ALMOST ALL STUDENTS WHO ARE ACCEPTED INTO MEDICAL SCHOOLS OBTAIN A MEDICAL DEGREE \n",
      "ALMOST ALL STUDENTS WHO ARE ACCEPTED INTO MEDICAL SCHOOLS OBTAIN A MEDICAL DEGREE \n",
      "======\n",
      "torch.Size([1153, 64, 40])\n",
      "=====\n",
      "DOCTOR PIERCE SAID READERS OF PHILIP MORRIS'S MAGAZINE PROBABLY ARE BETTER EDUCATED THAN THE TYPICAL SMOKER PERIOD \n",
      "DOCTOR PEAR SAID READERS OF FILLEPHAMIRISES MAGAZINE PROBABLY ARE BETTER EDUCATED THE NATIPICATED THE NATIPICAL SMOKER PERIOD \n",
      "======\n",
      "torch.Size([1080, 18, 40])\n",
      "=====\n",
      "DOUBLE-QUOTE HAVEN'T WE ALREADY GONE OVERBOARD IN S. B. A. BUDGET CUTS QUESTION-MARK DOUBLE-QUOTE \n",
      "DOUBLE-QUOTE HAVEN'T LE A RITY DONE OVERBOARD IN HASK B. A. BUDGET CATS CLASTION-MARK DOUBLE-QUOTE \n",
      "======\n",
      "\n",
      "Epoch     3: reducing learning rate of group 0 to 1.0000e-04.\n",
      "epoch 2: train loss : 0.2716, train perplexity : 1.1562, valid loss : 4.3617, valid perplexity: 108.23 valid distance : 12.87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973f98a74d1b4ebe8f705b58010b3016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "P. N. C.'S MERGER WITH CITIZENS LAST YEAR GAVE IT ACCESS TO THE THRIVING MID HYPHEN SOUTH REGION PERIOD \n",
      "P. N. C.'S MERGER WITH CITIZENS LAST YEAR GAVIN T ACCESS TO THE THRIVING MID HYPHEN SOUTH REGION PERIOD \n",
      "======\n",
      "0.2957105040550232\n",
      "0.21666871011257172\n",
      "0.24641340970993042\n",
      "0.22243475914001465\n",
      "0.22376132011413574\n",
      "0.21776805818080902\n",
      "0.19745168089866638\n",
      "0.22591395676136017\n",
      "0.20546755194664001\n",
      "0.2232978790998459\n",
      "0.2120232880115509\n",
      "0.21020616590976715\n",
      "0.18969805538654327\n",
      "0.1959037184715271\n",
      "0.24996982514858246\n",
      "0.192496657371521\n",
      "0.27565184235572815\n",
      "0.23428481817245483\n",
      "0.23316651582717896\n",
      "0.15325772762298584\n",
      "0.28169456124305725\n",
      "0.20304058492183685\n",
      "0.2419043332338333\n",
      "0.23974137008190155\n",
      "0.17602184414863586\n",
      "0.22536325454711914\n",
      "0.25026604533195496\n",
      "0.2443057745695114\n",
      "0.23873770236968994\n",
      "0.20914320647716522\n",
      "0.1828048974275589\n",
      "0.18811634182929993\n",
      "0.19959327578544617\n",
      "0.1813986748456955\n",
      "0.15150536596775055\n",
      "0.21635854244232178\n",
      "0.2954350709915161\n",
      "0.22435227036476135\n",
      "0.21302051842212677\n",
      "0.32367998361587524\n",
      "0.2315313071012497\n",
      "0.19082549214363098\n",
      "0.18178851902484894\n",
      "0.1813470870256424\n",
      "0.15421892702579498\n",
      "0.2042350471019745\n",
      "0.21771468222141266\n",
      "0.2188364565372467\n",
      "0.19440744817256927\n",
      "0.18138384819030762\n",
      "=====\n",
      "THE CITY SAYS THE SOCIETY AND ITS CELEBRITIES ARE ELITISTS WHO CAN SCARCELY CLAIM TO SPEAK FOR THE COMMON GOOD \n",
      "THE CITY SAYS THE SOCIETY AND ITS CELEBRITIES ARE ILETASE  WHO CAN SCARCELY CLAIN TO SPEAK FOR THE COMMON GOOD \n",
      "======\n",
      "0.19652174413204193\n",
      "0.1860559731721878\n",
      "0.1889965832233429\n",
      "0.24652700126171112\n",
      "0.19255170226097107\n",
      "0.24855808913707733\n",
      "0.19146761298179626\n",
      "0.22557100653648376\n",
      "0.23303204774856567\n",
      "0.2081279754638672\n",
      "0.20590467751026154\n",
      "0.20255878567695618\n",
      "0.2529183328151703\n",
      "0.16522075235843658\n",
      "0.15529173612594604\n",
      "0.211210235953331\n",
      "0.15267512202262878\n",
      "0.11898480355739594\n",
      "0.22898250818252563\n",
      "0.18511845171451569\n",
      "0.21146367490291595\n",
      "0.2614116966724396\n",
      "0.242397278547287\n",
      "0.18509936332702637\n",
      "0.2219548374414444\n",
      "0.1944103091955185\n",
      "0.15373048186302185\n",
      "0.20724298059940338\n",
      "0.24384090304374695\n",
      "0.1967466175556183\n",
      "0.14741738140583038\n",
      "0.21513444185256958\n",
      "0.16692551970481873\n",
      "0.2156245857477188\n",
      "0.19990316033363342\n",
      "0.2503935694694519\n",
      "0.23613713681697845\n",
      "0.27236407995224\n",
      "0.18371473252773285\n",
      "0.1866249293088913\n",
      "0.1651187241077423\n",
      "0.17882172763347626\n",
      "0.19466093182563782\n",
      "0.1634449064731598\n",
      "0.23679520189762115\n",
      "0.21866853535175323\n",
      "0.2024145871400833\n",
      "0.18696750700473785\n",
      "0.1852511763572693\n",
      "0.20783424377441406\n",
      "=====\n",
      "THEY CAN ALSO SHOW HOW THE SHAPE AND SIZE OF CONTINENTS AND OCEANS HAVE CHANGED OVER TIME \n",
      "THEY CAN ALSO SHOW HOW THE SHAPE AND SIZE OF CONTINENTS AND OCEANS HAVE CHANGED OVER TIME \n",
      "======\n",
      "0.20650185644626617\n",
      "0.2344864010810852\n",
      "0.18425583839416504\n",
      "0.21449753642082214\n",
      "0.15772219002246857\n",
      "0.19761669635772705\n",
      "0.18332825601100922\n",
      "0.17686212062835693\n",
      "0.2360287457704544\n",
      "0.15638819336891174\n",
      "0.1497032791376114\n",
      "0.16823126375675201\n",
      "0.17954137921333313\n",
      "0.1993759721517563\n",
      "0.1931375414133072\n",
      "0.2217719405889511\n",
      "0.2029690444469452\n",
      "0.1887565404176712\n",
      "0.17008008062839508\n",
      "0.18949398398399353\n",
      "0.2625713050365448\n",
      "0.17744943499565125\n",
      "0.16995371878147125\n",
      "0.17760111391544342\n",
      "0.13982997834682465\n",
      "0.18188554048538208\n",
      "0.22425606846809387\n",
      "0.20746740698814392\n",
      "0.23202183842658997\n",
      "0.159795880317688\n",
      "0.1834641396999359\n",
      "0.19007989764213562\n",
      "0.16200822591781616\n",
      "0.2167900800704956\n",
      "0.22488738596439362\n",
      "0.20475265383720398\n",
      "0.20605866611003876\n",
      "0.21742962300777435\n",
      "0.1803368777036667\n",
      "0.23450614511966705\n",
      "0.13614417612552643\n",
      "0.1805802285671234\n",
      "0.14709141850471497\n",
      "0.17320668697357178\n",
      "0.183622807264328\n",
      "0.23768427968025208\n",
      "0.193864107131958\n",
      "0.20482373237609863\n",
      "0.1625169962644577\n",
      "0.17114593088626862\n",
      "=====\n",
      "BUT SOME INDUSTRY ANALYSTS ARE SKEPTICAL ABOUT S. H. V.'S INTENTIONS PERIOD \n",
      "BUT SOME INDUSTRY ANALYSTS ORE SKEPTICAL ABOUT S. A. V. SIINTENTIONS <eos>ERIOD \n",
      "======\n",
      "0.33895212411880493\n",
      "0.16979821026325226\n",
      "0.21824686229228973\n",
      "0.28385597467422485\n",
      "0.17740462720394135\n",
      "0.17191767692565918\n",
      "0.19729283452033997\n",
      "0.17512373626232147\n",
      "0.19132713973522186\n",
      "0.16177518665790558\n",
      "0.17536893486976624\n",
      "0.13107074797153473\n",
      "0.24616575241088867\n",
      "0.18431179225444794\n",
      "0.172765851020813\n",
      "0.1594424843788147\n",
      "0.17538169026374817\n",
      "0.19202129542827606\n",
      "0.1856953203678131\n",
      "0.21044713258743286\n",
      "0.19508706033229828\n",
      "0.23228679597377777\n",
      "0.16885602474212646\n",
      "0.22687330842018127\n",
      "0.17588844895362854\n",
      "0.11118458211421967\n",
      "0.17994295060634613\n",
      "0.23890420794487\n",
      "0.17635118961334229\n",
      "0.17658865451812744\n",
      "0.14156107604503632\n",
      "0.17519263923168182\n",
      "0.2788931727409363\n",
      "0.17931951582431793\n",
      "0.22051917016506195\n",
      "0.20612448453903198\n",
      "0.15939222276210785\n",
      "0.2046726495027542\n",
      "0.2914056181907654\n",
      "0.2077915370464325\n",
      "0.18501053750514984\n",
      "0.20880481600761414\n",
      "0.17925730347633362\n",
      "0.24247953295707703\n",
      "0.18296481668949127\n",
      "0.19328780472278595\n",
      "0.19717371463775635\n",
      "0.164380744099617\n",
      "0.12510617077350616\n",
      "0.14741002023220062\n",
      "=====\n",
      "A VOTE FOR CONISTON PROBABLY MEANS A TAKEOVER OR RESTRUCTURING AND A QUICK PROFIT \n",
      "A VOTE FOR CONISTON PROBABLY MEANS A TAKEOVER OR RESTRUCTURING AND A QUICK PROFIT \n",
      "======\n",
      "0.18139688670635223\n",
      "0.1652839630842209\n",
      "0.1395677626132965\n",
      "0.20675808191299438\n",
      "0.153202086687088\n",
      "0.16479507088661194\n",
      "0.19851167500019073\n",
      "0.171688511967659\n",
      "0.18358832597732544\n",
      "0.1772465854883194\n",
      "0.17474523186683655\n",
      "0.18559855222702026\n",
      "0.15027859807014465\n",
      "0.16870947182178497\n",
      "0.19081255793571472\n",
      "0.18923279643058777\n",
      "0.18616165220737457\n",
      "0.17690226435661316\n",
      "0.19731028378009796\n",
      "0.22099332511425018\n",
      "0.2131044715642929\n",
      "0.158406600356102\n",
      "0.28153276443481445\n",
      "0.17465044558048248\n",
      "0.20113182067871094\n",
      "0.1923416703939438\n",
      "0.1862000823020935\n",
      "0.17050698399543762\n",
      "0.16316646337509155\n",
      "0.21797512471675873\n",
      "0.18998704850673676\n",
      "0.18522843718528748\n",
      "0.19803708791732788\n",
      "0.20143893361091614\n",
      "0.14653781056404114\n",
      "0.1453457921743393\n",
      "0.17234273254871368\n",
      "0.12861616909503937\n",
      "0.20596544444561005\n",
      "0.18683195114135742\n",
      "0.16920484602451324\n",
      "0.14348803460597992\n",
      "0.20910225808620453\n",
      "0.17940710484981537\n",
      "0.16365058720111847\n",
      "0.16126035153865814\n",
      "0.14361725747585297\n",
      "0.24853835999965668\n",
      "0.1788588911294937\n",
      "0.19337937235832214\n",
      "=====\n",
      "MR. REAGAN HAD NO COATTAILS IN NINETEEN EIGHTY FOUR WHEN HE WAS AT THE TOP OF THE TICKET REPUBLICANS GAINED ONLY FOURTEEN HOUSE SEATS AND LOST TWO SENATE SEATS \n",
      "MR. REAGAN HAD NO COTTAAILS IN NINETEEN EIGHTY FOUR WHEN HE WAS AT THE TOP OF THE TICKET REPUBLICANS GAINED ONLY FOURTEEN HOUSE SEETS AND LOST TWO SENATE SEATS \n",
      "======\n",
      "0.13858146965503693\n",
      "0.17621085047721863\n",
      "0.1842598170042038\n",
      "0.14086148142814636\n",
      "0.17441880702972412\n",
      "0.21337778866291046\n",
      "0.15007176995277405\n",
      "0.18301275372505188\n",
      "0.15064740180969238\n",
      "0.20187702775001526\n",
      "0.14567171037197113\n",
      "0.1581142544746399\n",
      "0.18755415081977844\n",
      "0.14645537734031677\n",
      "0.16124941408634186\n",
      "0.2276451289653778\n",
      "0.2111862301826477\n",
      "0.14422236382961273\n",
      "0.16075651347637177\n",
      "0.1648731678724289\n",
      "0.15321952104568481\n",
      "0.19001911580562592\n",
      "0.19584041833877563\n",
      "0.27020978927612305\n",
      "0.21282117068767548\n",
      "0.17388007044792175\n",
      "0.16547605395317078\n",
      "0.13739822804927826\n",
      "0.19337163865566254\n",
      "0.14469459652900696\n",
      "0.2562468945980072\n",
      "0.24654017388820648\n",
      "0.18101844191551208\n",
      "0.16519299149513245\n",
      "0.14912942051887512\n",
      "0.1516786813735962\n",
      "0.1868780106306076\n",
      "0.1667596846818924\n",
      "0.176276296377182\n",
      "0.20040230453014374\n",
      "0.2018163651227951\n",
      "0.18743520975112915\n",
      "0.1824292689561844\n",
      "0.22634060680866241\n",
      "0.161849245429039\n",
      "0.18314754962921143\n",
      "0.13022509217262268\n",
      "0.1932983100414276\n",
      "0.15725556015968323\n",
      "0.15645001828670502\n",
      "=====\n",
      "STILL COMMA MR. JOSEPHS AND OTHERS THINK THAT THE CHANGES WILL BE GOOD FOR THE FARM ECONOMY IN GENERAL PERIOD \n",
      "STILL COMMA MR. JOSEPHS AND OTHERS THINK THAT THE CHANGES WILL BE GOOD FOR THE FAR MECONOMY IN GENERAL PERIOD \n",
      "======\n",
      "0.1719931811094284\n",
      "0.18703021109104156\n",
      "0.17939025163650513\n",
      "0.22507627308368683\n",
      "0.178269162774086\n",
      "0.17177928984165192\n",
      "0.16033342480659485\n",
      "0.20927751064300537\n",
      "0.17195039987564087\n",
      "0.17715764045715332\n",
      "0.12847208976745605\n",
      "0.14195923507213593\n",
      "0.1742122918367386\n",
      "0.1974845975637436\n",
      "0.23067215085029602\n",
      "0.13946427404880524\n",
      "0.1629951447248459\n",
      "0.16404864192008972\n",
      "0.18751052021980286\n",
      "0.2215159833431244\n",
      "0.22491538524627686\n",
      "0.16989248991012573\n",
      "0.24155251681804657\n",
      "0.15306153893470764\n",
      "0.17534032464027405\n",
      "0.15886905789375305\n",
      "0.17256727814674377\n",
      "0.13318514823913574\n",
      "0.15894490480422974\n",
      "0.16414202749729156\n",
      "0.17261558771133423\n",
      "0.1603434830904007\n",
      "0.1743277907371521\n",
      "0.16862715780735016\n",
      "0.14701266586780548\n",
      "0.1825619786977768\n",
      "0.22189582884311676\n",
      "0.26609957218170166\n",
      "0.12139005213975906\n",
      "0.1568012833595276\n",
      "0.14565511047840118\n",
      "0.1792299896478653\n",
      "0.14459699392318726\n",
      "0.15523502230644226\n",
      "0.16027848422527313\n",
      "0.16695687174797058\n",
      "0.15443739295005798\n",
      "0.15270942449569702\n",
      "0.13938501477241516\n",
      "0.17216265201568604\n",
      "=====\n",
      "ANALYSTS HAD BEEN PREDICTING HIGHER PRICES THIS YEAR THOUGH NOT THIS HIGH \n",
      "ANALYSTS HAD BEEN PREDICTING HIGHER PRICES THIS YEAR THOUGH NOT THIS HIGH \n",
      "======\n",
      "0.16689634323120117\n",
      "0.19658872485160828\n",
      "0.2316744476556778\n",
      "0.19588996469974518\n",
      "0.19992458820343018\n",
      "0.14253005385398865\n",
      "0.18030917644500732\n",
      "0.18700195848941803\n",
      "0.23158948123455048\n",
      "0.1743057817220688\n",
      "0.2109290212392807\n",
      "0.1359124630689621\n",
      "0.15510430932044983\n",
      "0.14572755992412567\n",
      "0.22938446700572968\n",
      "0.170381560921669\n",
      "0.16222208738327026\n",
      "0.15097828209400177\n",
      "0.15597859025001526\n",
      "0.19303005933761597\n",
      "0.1970716267824173\n",
      "0.2736233174800873\n",
      "0.1467735469341278\n",
      "0.16008082032203674\n",
      "0.14854754507541656\n",
      "0.19906555116176605\n",
      "0.17763005197048187\n",
      "0.1973269134759903\n",
      "0.20029808580875397\n",
      "0.20690762996673584\n",
      "0.12907646596431732\n",
      "0.13930648565292358\n",
      "0.20126554369926453\n",
      "0.1985676884651184\n",
      "0.15196093916893005\n",
      "0.1660972386598587\n",
      "0.3408990204334259\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5cde7527ce466899242a34b20bc2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1043, 64, 40])\n",
      "=====\n",
      "PAINEWEBBER WAS ONE OF THE EARLY WALL STREET FIRMS TO GET INTO VENTURE CAPITAL \n",
      "PAIN WEBBER WAS ONE OF THE EARLY WALL STREET FIRMS TO GET INTEVENTURE CAPITA \n",
      "======\n",
      "torch.Size([1237, 64, 40])\n",
      "=====\n",
      "MUCH OF THE GROUND BEEF CONSUMED IN THE UNITED STATES COMES FROM DAIRY COWS \n",
      "MUCH OF THE GROUND BEEF CONSUMED THE UNITED STATES COMES FROM DAIRY COWS \n",
      "======\n",
      "torch.Size([1335, 64, 40])\n",
      "=====\n",
      "FOR INVESTORS WILLING TO TAKE MORE RISK COMMA THE NEARBY CONTRACT MONTH COMMA WHICH TRADED WITHOUT PRICE LIMITS COMMA WAS ONE ALTERNATIVE PERIOD \n",
      "FOR INVESTOR LINETO TAKE MORE RIS COMMA THE NEARBY CONTRACT MONTH COMMA WHICH TRADED WITHOUT PRISELY MITS COMMA WILL WALL TERNATIVE PERIOD \n",
      "======\n",
      "torch.Size([1166, 64, 40])\n",
      "=====\n",
      "IN ONE SENSE THE U. S. ADMINISTRATION'S SUPPORT OF THE MEXICAN PLAN ISOLATES BANKAMERICA AND MANUFACTURERS HANOVER \n",
      "IN ONE CENTS THE USEM DADMINISTRATION SUPPORT OF THE MEXT CONPLAN I FLAIDS BANK AMERICA  MANUFACTORS AND OVER \n",
      "======\n",
      "torch.Size([1179, 64, 40])\n",
      "=====\n",
      "THE ENORMOUS AMOUNTS OF CARBON DIOXIDE IN THE ATMOSPHERE CAUSE THIS HIGH PRESSURE \n",
      "THE ENORMOUS AMOUNTS OF CARBON DIXIDE IN THE ATMOSPHERE CAUSE THIS HIGH PRESSION \n",
      "======\n",
      "torch.Size([1350, 64, 40])\n",
      "=====\n",
      "AFTER THE I. B. M. PERSONAL COMPUTER CAME OUT IN NINETEEN EIGHTY TWO COMMA MESSRS. PERIOD \n",
      "AFTER THE A. B. M. PERSONAL COMPUTER A. KAMO IN NINETEEN EIGHTY TWO COMMA MASSERS PERIOD \n",
      "======\n",
      "torch.Size([1579, 64, 40])\n",
      "=====\n",
      "THE STATUE OF LIBERTY AND ELLIS ISLAND ARE WITHIN THE NEW JERSEY WATERS OF NEW YORK BAY \n",
      "THE STATUE OF LIBERTY CHM A ELLS ISLAND ARE WITHID IN THE NEW JERSEY WARDERS OF NEW YORK BAY \n",
      "======\n",
      "torch.Size([1743, 64, 40])\n",
      "=====\n",
      "HE SAID MORTON THIOKOL HAS ENOUGH AMMONIUM PERCHLORATE FOR THREE SHUTTLE MISSIONS PERIOD \n",
      "HE SAID WARTEN IT FICCOLE HAS YEENOUGH OR MONEY PERCCLORIET FOUR THREE SHOTTLEMITIONS PERIOD \n",
      "======\n",
      "torch.Size([1447, 64, 40])\n",
      "=====\n",
      "THE RECENT ABUSES ON WALL STREET HAVE MADE IT A POSSIBLE TARGET FOR A NECESSARY TAX INCREASE \n",
      "THE RECENT BUSUSES ON WALL STREET OBMATED A POSSIBLE CARGET FOR AN NECESSARY TAX INCREASE \n",
      "======\n",
      "torch.Size([1439, 64, 40])\n",
      "=====\n",
      "A SPOKESMAN FOR THE G. M. GROUP SAID THE REDEVELOPMENT IS CONTINGENT ON RECEIVING CERTAIN TAX ABATEMENTS FROM THE CITY AND STATE PERIOD \n",
      "A SPOKESMAN FOR THE G. M. GROUPS AS THE REDEVELOPMENT IS CONTENGINETON OR SEEVING CERTAIN TAX ABATEMENTS FROM THE CITY AND STATE PERIOD \n",
      "======\n",
      "torch.Size([1333, 64, 40])\n",
      "=====\n",
      "ALL THE BONDS WILL BE DATED NEXT MONDAY \n",
      "ALL THE BONDS WILL BE DATED NEXT MONDAY \n",
      "======\n",
      "torch.Size([1237, 64, 40])\n",
      "=====\n",
      "BOTH PETROLEUM AND NATURAL GAS DEPOSITS ARE SCATTERED THROUGH EASTERN OHIO \n",
      "BOTH PETROLEUM AND NATURAL GAS DEPOSITS S S S S S SCATTERED THROUGH EASTERN OHIO \n",
      "======\n",
      "torch.Size([1236, 64, 40])\n",
      "=====\n",
      "THE THRIFT BAILOUT BILL WAS SENT TO BUSH WHO IS EXPECTED TO SIGN IT AS SOON AS WEDNESDAY \n",
      "THE FIRTH BAIL OUT BILL WITH SENT TO BUSH WHO IS EXPECTED TO SUN IT IS WEDNESDAY \n",
      "======\n",
      "torch.Size([1567, 64, 40])\n",
      "=====\n",
      "MUCH OF THE GROUND BEEF CONSUMED IN THE UNITED STATES COMES FROM DAIRY COWS \n",
      "MUCH OF THE GROUND BEEF CONSUMED IN THE UNUOUST DATES COMES FROM DAIRY COWNS \n",
      "======\n",
      "torch.Size([1376, 64, 40])\n",
      "=====\n",
      "THE ACTION REPRESENTED A TOUGHER STANCE AGAINST FINANCIAL INSTITUTIONS PERIOD \n",
      "THE ACTION REPRESENTED A TUULIFER STANCE AGAIST FINANCIAL IS TITATIONS PERIOD \n",
      "======\n",
      "torch.Size([1443, 64, 40])\n",
      "=====\n",
      "ALMOST ALL STUDENTS WHO ARE ACCEPTED INTO MEDICAL SCHOOLS OBTAIN A MEDICAL DEGREE \n",
      "ALMOST ALL STUDENTS WHO ARE ACCEPTED INTO MEDICAL SCHOOLS OBTAIN A MEDICAL DEGREE \n",
      "======\n",
      "torch.Size([1153, 64, 40])\n",
      "=====\n",
      "DOCTOR PIERCE SAID READERS OF PHILIP MORRIS'S MAGAZINE PROBABLY ARE BETTER EDUCATED THAN THE TYPICAL SMOKER PERIOD \n",
      "DOCTOR PEAR SAID READERS OF HELLUPMERISES MAGAZINE PROBABLY ARE BETTER EDUCATED THE THE TYPICAL SMOKER PERIOD \n",
      "======\n",
      "torch.Size([1080, 18, 40])\n",
      "=====\n",
      "DOUBLE-QUOTE HAVEN'T WE ALREADY GONE OVERBOARD IN S. B. A. BUDGET CUTS QUESTION-MARK DOUBLE-QUOTE \n",
      "DOUBLE-QUOTE HAVEN'T WE ARTI DON'T OVERBOARD IN ASKED BE ABBUDGET CATS QUESTION-MARK DOUBLE-QUOTE \n",
      "======\n",
      "\n",
      "epoch 3: train loss : 0.1906, train perplexity : 1.1073, valid loss : 4.3516, valid perplexity: 117.80 valid distance : 10.21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebc474ad19140908483d62a0700a4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "PHILOSOPHERS OF EDUCATION OFTEN DIFFER IN THEIR VIEWS ON THE NATURE OF KNOWLEDGE \n",
      "PHILOSOPHERS OF EDUCATION OFTEN DIFFER IN THEIR VIEWS ON THE NATURE OF KNOWLEDGE \n",
      "======\n",
      "0.21108156442642212\n",
      "0.19690877199172974\n",
      "0.11958964169025421\n",
      "0.16798503696918488\n",
      "0.14637507498264313\n",
      "0.18679717183113098\n",
      "0.15929493308067322\n",
      "0.16076044738292694\n",
      "0.17127877473831177\n",
      "0.140704944729805\n",
      "0.1855994313955307\n",
      "0.17050617933273315\n",
      "0.14416556060314178\n",
      "0.17253975570201874\n",
      "0.25059932470321655\n",
      "0.14550605416297913\n",
      "0.14178623259067535\n",
      "0.13688504695892334\n",
      "0.1668386608362198\n",
      "0.18115033209323883\n",
      "0.20015180110931396\n",
      "0.19376088678836823\n",
      "0.24234478175640106\n",
      "0.15519392490386963\n",
      "0.1565723419189453\n",
      "0.15509240329265594\n",
      "0.16573035717010498\n",
      "0.24360617995262146\n",
      "0.13959351181983948\n",
      "0.19003820419311523\n",
      "0.1929168999195099\n",
      "0.16576050221920013\n",
      "0.18515774607658386\n",
      "0.16863863170146942\n",
      "0.13171932101249695\n",
      "0.12055066227912903\n",
      "0.2051866352558136\n",
      "0.13996702432632446\n",
      "0.1257396936416626\n",
      "0.17377786338329315\n",
      "0.13038772344589233\n",
      "0.16380053758621216\n",
      "0.15226121246814728\n",
      "0.18659354746341705\n",
      "0.18229158222675323\n",
      "0.1490975171327591\n",
      "0.14313693344593048\n",
      "0.16642990708351135\n",
      "0.16635781526565552\n",
      "0.149733766913414\n",
      "=====\n",
      "NEXT YEAR COMMA IF WE DO WELL COMMA THERE MAY BE A BIGGER CHECK PERIOD DOUBLE-QUOTE \n",
      "NEXT YEAR COMMA IS WE DO WELL COMMA THERE MAY BE A BIGGER CHECK PERIOD DOUBLE-QUOTE \n",
      "======\n",
      "0.21228165924549103\n",
      "0.1455412209033966\n",
      "0.1810489147901535\n",
      "0.17107424139976501\n",
      "0.19341658055782318\n",
      "0.13934600353240967\n",
      "0.14635324478149414\n",
      "0.17320583760738373\n",
      "0.1546785831451416\n",
      "0.1982485055923462\n",
      "0.17126309871673584\n",
      "0.16747502982616425\n",
      "0.14888958632946014\n",
      "0.15488217771053314\n",
      "0.1594938337802887\n",
      "0.21989181637763977\n",
      "0.22429846227169037\n",
      "0.13882842659950256\n",
      "0.2569819688796997\n",
      "0.17913582921028137\n",
      "0.16899855434894562\n",
      "0.17331373691558838\n",
      "0.14693669974803925\n",
      "0.1269821673631668\n",
      "0.14848342537879944\n",
      "0.20329570770263672\n",
      "0.168626606464386\n",
      "0.21952949464321136\n",
      "0.16878560185432434\n",
      "0.13831080496311188\n",
      "0.13776475191116333\n",
      "0.17855589091777802\n",
      "0.13106903433799744\n",
      "0.1862092912197113\n",
      "0.1540534645318985\n",
      "0.17041796445846558\n",
      "0.16739344596862793\n",
      "0.17034299671649933\n",
      "0.22280173003673553\n",
      "0.17531216144561768\n",
      "0.17160117626190186\n",
      "0.2251468449831009\n",
      "0.1503940373659134\n",
      "0.12837718427181244\n",
      "0.1592547446489334\n",
      "0.17681199312210083\n",
      "0.16878162324428558\n",
      "0.15424619615077972\n",
      "0.17502005398273468\n",
      "0.16347074508666992\n",
      "=====\n",
      "IT SIMPLY EXTENDED ITS CONTRACT WITH NATIONAL CARTING PERIOD \n",
      "IT SIMPLY EXTENDED ITS CONTRACT WITH NATIONAL CARTING PERIOD \n",
      "======\n",
      "0.1404864490032196\n",
      "0.1703995317220688\n",
      "0.1582111269235611\n",
      "0.16087286174297333\n",
      "0.17127569019794464\n",
      "0.17870929837226868\n",
      "0.1788705587387085\n",
      "0.1748836189508438\n",
      "0.10410647094249725\n",
      "0.21128195524215698\n",
      "0.12228123843669891\n",
      "0.2011672407388687\n",
      "0.1229289099574089\n",
      "0.15697471797466278\n",
      "0.24582906067371368\n",
      "0.13482269644737244\n",
      "0.17234575748443604\n",
      "0.13878671824932098\n",
      "0.13243941962718964\n",
      "0.11828166246414185\n",
      "0.1170785054564476\n",
      "0.21021579205989838\n",
      "0.17237447202205658\n",
      "0.19927524030208588\n",
      "0.13050924241542816\n",
      "0.13844181597232819\n",
      "0.171212300658226\n",
      "0.13346070051193237\n",
      "0.12956508994102478\n",
      "0.16964897513389587\n",
      "0.17049109935760498\n",
      "0.1645229011774063\n",
      "0.1390698403120041\n",
      "0.15778011083602905\n",
      "0.1765194833278656\n",
      "0.16081225872039795\n",
      "0.11867549270391464\n",
      "0.17470157146453857\n",
      "0.15170595049858093\n",
      "0.1205470860004425\n",
      "0.1641162931919098\n",
      "0.19210952520370483\n",
      "0.2927453815937042\n",
      "0.14373141527175903\n",
      "0.2842017114162445\n",
      "0.17685920000076294\n",
      "0.13842447102069855\n",
      "0.1729518175125122\n",
      "0.157242089509964\n",
      "0.1419084519147873\n",
      "=====\n",
      "IN ATLANTA COMMA A SPOKESMAN FOR DELTA AIR LINES SAID THE CARRIER WILL WAIT TO SEE DETAILS OF EASTERN'S FARES BEFORE DECIDING WHETHER TO MATCH THEM PERIOD \n",
      "IN ANLANTA COMMA A SPOKESMAN FOR DELTA AIRLLINE  SAID THE CARRIER WILL WAIT TO SEE DETAILS OF EASTERN S FAIES BEFORE DECIDING WHETHER TO MATCH THEM PERIOD \n",
      "======\n",
      "0.16425573825836182\n",
      "0.140021413564682\n",
      "0.15255975723266602\n",
      "0.17274218797683716\n",
      "0.1644723266363144\n",
      "0.14408180117607117\n",
      "0.18743212521076202\n",
      "0.11061691492795944\n",
      "0.1433044970035553\n",
      "0.17879045009613037\n",
      "0.1731308400630951\n",
      "0.2108771800994873\n",
      "0.19732706248760223\n",
      "0.15344789624214172\n",
      "0.13813644647598267\n",
      "0.16272477805614471\n",
      "0.1454576849937439\n",
      "0.15205636620521545\n",
      "0.14065107703208923\n",
      "0.2182687669992447\n",
      "0.1510351002216339\n",
      "0.1440606415271759\n",
      "0.15131482481956482\n",
      "0.13260720670223236\n",
      "0.14728708565235138\n",
      "0.17475992441177368\n",
      "0.16734161972999573\n"
     ]
    }
   ],
   "source": [
    "mean_train_losses = []\n",
    "mean_train_perplexity = []\n",
    "mean_valid_losses = []\n",
    "mean_valid_distance = []\n",
    "mean_valid_perplexity = []\n",
    "epochs = 24\n",
    "best_model = None\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_perplexity = []\n",
    "    for k, (x_batch, x_len, y_batch, y_len) in tqdm(enumerate(train_dataloader)):\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            optimizer.zero_grad()\n",
    "            x_batch = x_batch.cuda() #T, N, 40\n",
    "            y_batch = y_batch.cuda() #L, N\n",
    "            predictions, attentions = model(x_batch, x_len, text_input=y_batch, isTrain=True, tf = 0.4) # N, L-1, dim\n",
    "            labels = y_batch.transpose(0,1)[:, 1:]\n",
    "            loss = criterion(predictions.contiguous().view(-1, len(vocab)), labels.contiguous().view(-1)) \n",
    "            mask = torch.zeros(labels.size())\n",
    "            for i in range(len(y_len)):\n",
    "                mask[i, :y_len[i]-1] = 1\n",
    "            mask = mask.view(-1).cuda()\n",
    "            masked_loss = loss * mask\n",
    "            loss = torch.sum(masked_loss)\n",
    "            loss = loss/torch.sum(mask)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm(model.parameters(), 2)\n",
    "            \n",
    "            \n",
    "            perplexity = torch.exp(torch.mean(masked_loss))\n",
    "            \n",
    "            if k %50 == 0:\n",
    "                _, output = torch.max(predictions, dim=2)\n",
    "\n",
    "                pred = \"\".join(vocab.char_list[x] for x in output[0][:y_len[0]-2].tolist())\n",
    "                true = \"\".join(vocab.char_list[x] for x in labels[0][:y_len[0]-2].tolist())\n",
    "                print (\"=====\")\n",
    "                print (\"%s\\n%s\"%(true,pred))\n",
    "                print (\"======\")\n",
    "            \n",
    "            train_perplexity.append(perplexity.item())\n",
    "            train_losses.append(loss.item())\n",
    "            print (np.mean(loss.item()))\n",
    "            plot_weights(attentions.detach().cpu().numpy()[:, -1], epoch)\n",
    "            plot_grad_flow(model.named_parameters())\n",
    "            optimizer.step()\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    valid_losses = []\n",
    "    valid_distance = []\n",
    "    valid_perplexity = []\n",
    "    with torch.no_grad():\n",
    "        for k, (x_batch, x_len, y_batch, y_len) in tqdm(enumerate(dev_dataloader)):\n",
    "            x_batch = x_batch.cuda() #T, N, 40\n",
    "            y_batch = y_batch.cuda() #N, L\n",
    "            print (x_batch.shape)\n",
    "            predictions, _ = model(x_batch, x_len, text_input = y_batch, isTrain=False) # N, L-1, dim\n",
    "            predictions = predictions[:, :y_batch.shape[0]-1, :]\n",
    "            labels = y_batch.transpose(0,1)[:, 1:]\n",
    "            loss = criterion(predictions.contiguous().view(-1, len(vocab)), labels.contiguous().view(-1)) \n",
    "            mask = torch.zeros(labels.size())\n",
    "            for i in range(len(y_len)):\n",
    "                mask[i, :y_len[i]-1] = 1\n",
    "            mask = mask.view(-1).cuda()\n",
    "            masked_loss = loss * mask\n",
    "            loss = torch.sum(masked_loss)/torch.sum(mask)\n",
    "            perplexity = torch.mean(torch.exp(loss))\n",
    "            \n",
    "            _, output = torch.max(predictions, dim=2)\n",
    "            \n",
    "            preds = []\n",
    "            reals = []\n",
    "            #print (labels.shape)\n",
    "            #print (output.shape)\n",
    "            for i in range(output.size(0)):\n",
    "                end_pos = (output[i].tolist().index(vocab.char2idx['<eos>']) if vocab.char2idx['<eos>'] in output[i].tolist() else output[i].size(0))\n",
    "                pred = \"\".join(vocab.char_list[x] for x in output[i].tolist()[:end_pos])\n",
    "                true = \"\".join(vocab.char_list[x] for x in labels[i][:y_len[i]-2].tolist())\n",
    "                preds.append(pred)\n",
    "                reals.append(true)\n",
    "            print (\"=====\")\n",
    "            print (\"%s\\n%s\"%(true,pred))\n",
    "            print (\"======\")\n",
    "            valid_distance.append(get_distance(preds,reals))\n",
    "            valid_losses.append(loss.item())\n",
    "            valid_perplexity.append(perplexity.item())\n",
    "    \n",
    "    mean_train_losses.append(np.mean(train_losses))\n",
    "    mean_valid_losses.append(np.mean(valid_losses))\n",
    "    mean_valid_perplexity.append(np.mean(valid_perplexity))\n",
    "    mean_valid_distance.append(np.mean(valid_distance))\n",
    "    scheduler.step(np.mean(valid_distance))\n",
    "    if (best_model is None) or (np.mean(valid_distance) < min(mean_valid_distance)):\n",
    "        best_model = model\n",
    "\n",
    "    \n",
    "    print('epoch {}: train loss : {:.4f}, train perplexity : {:.4f}, valid loss : {:.4f}, valid perplexity: {:.2f} valid distance : {:.2f}'\\\n",
    "         .format(epoch+1, np.mean(train_losses),np.mean(train_perplexity), np.mean(valid_losses), np.mean(valid_perplexity), np.mean(valid_distance)))\n",
    "\n",
    "    torch.save(model.state_dict(), MODEL_PATH+'%d_%d.pt'%(int(time.time()), epoch))\n",
    "torch.save(best_model.state_dict(), MODEL_PATH+'best_%d.pt'%int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH+'%d_%d.pt'%(int(time.time()), epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = load_data(DATA_PATH+\"test_new.npy\")\n",
    "test_dataloader = DataLoader(Speech2TextDataset(text_x, isTrain = False), \n",
    "                              shuffle=False, \n",
    "                              batch_size=BATCH_SIZE, \n",
    "                              collate_fn = collate_pad,\n",
    "                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, _ in test_dataloader:\n",
    "    print (x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for k, (x_batch, x_len) in tqdm(enumerate(test_dataloader)):\n",
    "        x_batch = x_batch.cuda() #T, N, 40\n",
    "        predictions, _ = model(x_batch, x_len, text_input = y_batch, isTrain=False) # N, L-1, dim\n",
    "        predictions = predictions[:, :y_batch.shape[0]-1, :]\n",
    "        _, output = torch.max(predictions, dim=2)\n",
    "        for i in range(output.size(0)):\n",
    "            end_pos = (output[i].tolist().index(vocab.char2idx['<eos>']) if vocab.char2idx['<eos>'] in output[i].tolist() else output[i].size(0))\n",
    "            pred = \"\".join(vocab.char_list[x] for x in output[i].tolist()[:end_pos])\n",
    "            preds.append(pred)\n",
    "out_df = pd.DataFrame()\n",
    "out_df['Id'] = np.arange(0, len(test_x))\n",
    "out_df['Predicted'] = preds\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_PATH = \"submission/\"\n",
    "file_name = SUBMISSION_PATH+\"submission_%d.csv\"%int(time.time())\n",
    "out_df.to_csv(file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "hw4p2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "27550cb8dde74363ad9cb032d24030ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7eded93b134746fabbac42e2fd1d07d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b285a9ba3d544618baf476d6b03a171": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3d38560348145d49262c0085578d637",
       "IPY_MODEL_adc9b4ca642b4d3888501984e2eae60b"
      ],
      "layout": "IPY_MODEL_ffa808d8bc04498ca24a2030f8f5309a"
     }
    },
    "adc9b4ca642b4d3888501984e2eae60b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efc3f992949c441a85d00fb0bbe66570",
      "placeholder": "",
      "style": "IPY_MODEL_d4516f08803141b4bf10a3f8be134994",
      "value": " 196/387 [23:08&lt;21:57,  6.90s/it]"
     }
    },
    "d4516f08803141b4bf10a3f8be134994": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efc3f992949c441a85d00fb0bbe66570": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f3d38560348145d49262c0085578d637": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": " 51%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7eded93b134746fabbac42e2fd1d07d2",
      "max": 387,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_27550cb8dde74363ad9cb032d24030ea",
      "value": 197
     }
    },
    "ffa808d8bc04498ca24a2030f8f5309a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
