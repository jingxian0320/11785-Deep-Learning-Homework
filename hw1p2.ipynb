{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# README\n",
    "\n",
    "## Model Hyperparameters\n",
    "* Layers -> [1240, 2048, 2048, 1024, 1024, 512, 138]\n",
    "\n",
    "* ReLU activations\n",
    "\n",
    "* BatchNorm1d in between layers, after the activations\n",
    "\n",
    "* Dropout rate -> [0, 0, 0.1, 0, 0.2, 0, 0]\n",
    "\n",
    "* Context size k = 15 frames on both sides\n",
    "\n",
    "* Adam optimizer, with the default learning rate 1e-3\n",
    "\n",
    "* Two runs of tuning learning rate: 1st --> step_size = 8, 2nd --> step_size = 4\n",
    "\n",
    "* epoch = 12\n",
    "\n",
    "* batch_size = 128\n",
    "\n",
    "## Experimentation\n",
    "\n",
    "The script consists of environmental setup, data loading, model building, and result output. \n",
    "\n",
    "Data Loading: \n",
    "\n",
    "* Create training and validation dataset (9: 1)\n",
    "\n",
    "* Create data loaders that generate a batch of frames for training\n",
    "\n",
    "Model Building:\n",
    "\n",
    "Two rounds of model tuning are carried out with different step_size for scheduler. In the first round, step_size = 8 is used and Xavier is utilized for paremeter initialization. In the 2nd round, it uses the 1st model as the pre-trained model and the step_size of scheduler is set as 4. \n",
    "\n",
    "Result Output:\n",
    "\n",
    "Read the test file and write the model predictions to file.\n",
    "\n",
    "\n",
    "## Guidelines for Running\n",
    "The script can only function under CUDA environment. Please change the directory paths (DATA_PATH, MODEL_PATH, SUBMISSION_PATH), for data, model, and submission files respectively for your environment. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environmental Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "MODEL_PATH = \"model/\"\n",
    "SUBMISSION_PATH = \"submission/\"\n",
    "num_workers = 4\n",
    "batch_size = 128\n",
    "K = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "# set SEED\n",
    "os.environ[\"SEED\"] = \"999\"\n",
    "torch.manual_seed(999)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(x_path,y_path=\"\"):\n",
    "    x = np.load(x_path, allow_pickle=True)\n",
    "    print (\"Number of utterances \" + str(x.shape[0]))\n",
    "    print (\"Number of dimentions \" + str(x[0].shape[1]))\n",
    "    print (\"Avg length of utterances \" + str(np.mean([i.shape[0] for i in x])))\n",
    "    if y_path:\n",
    "        y = np.load(y_path, allow_pickle=True)\n",
    "        return x, y\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of utterances 1100\n",
      "Number of dimentions 40\n",
      "Avg length of utterances 614.3963636363636\n"
     ]
    }
   ],
   "source": [
    "dev_x, dev_y = load_data(DATA_PATH+\"dev.npy\",y_path=DATA_PATH+\"dev_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of utterances 24500\n",
      "Number of dimentions 40\n",
      "Avg length of utterances 628.1107346938776\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = load_data(DATA_PATH+\"train.npy\",y_path=DATA_PATH+\"train_labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.append(train_x, dev_x)\n",
    "data_y = np.append(train_y, dev_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, k, x, y=None):\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self._x = x.copy()\n",
    "        if y is not None:\n",
    "            self._y = y.copy()\n",
    "        else:\n",
    "            self._y = None\n",
    "        self.n_dim = len(self._x[0][0])\n",
    "        self.output_dim = self.n_dim * (2*self.k+1)\n",
    "        self.utterance_count = len(self._x)\n",
    "        self.utterance_start_pos = self.get_utterance_start_pos()\n",
    "        self.frame_count = self.utterance_start_pos[-1] + len(self._x[-1])\n",
    "        self.outcomes = np.arange(138)\n",
    "        self.zero_padding()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.frame_count\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        utterance_id, frame_id = self.refactor_index(index)\n",
    "        x_item = self._x[utterance_id][frame_id:(frame_id + self.k * 2 + 1)]\n",
    "        if self._y is not None:\n",
    "            return torch.from_numpy(x_item), self._y[utterance_id][frame_id]\n",
    "        else:\n",
    "            return x_item\n",
    "    \n",
    "    def get_utterance_start_pos(self):\n",
    "        utterance_start_pos = []\n",
    "        size = 0\n",
    "        for i in range(len(self._x)):\n",
    "            utterance_start_pos.append(size)\n",
    "            size += len(self._x[i])\n",
    "        return utterance_start_pos\n",
    "    \n",
    "    def zero_padding(self):\n",
    "        for i in range(len(self._x)):\n",
    "            self._x[i] = np.concatenate([np.zeros((self.k, self.n_dim)), self._x[i], np.zeros((self.k, self.n_dim))])\n",
    "            if self._y is not None:\n",
    "                self._y[i] = torch.tensor(self._y[i]).long()\n",
    "        \n",
    "    def refactor_index(self, i):\n",
    "        left = 0\n",
    "        right = len(self.utterance_start_pos)\n",
    "        while (left < right - 1):\n",
    "            mid = (right + left)//2\n",
    "            mid_val = self.utterance_start_pos[mid]\n",
    "            if  mid_val == i:\n",
    "                return mid, 0\n",
    "            elif i < mid_val:\n",
    "                right = mid\n",
    "            else:\n",
    "                left = mid\n",
    "        return left, i - self.utterance_start_pos[left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14458094\n",
      "1606455\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MyDataset(K, data_x, data_y)\n",
    "train_set_size = int(len(train_dataset)*0.9)\n",
    "train_set, val_set = torch.utils.data.random_split(train_dataset, [train_set_size, len(train_dataset) - train_set_size])\n",
    "\n",
    "print (len(train_set))\n",
    "print (len(val_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 40])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print (train_dataset[0][0].shape)\n",
    "print (train_dataset[0][1].shape)\n",
    "#print (train_dataset[0][0])\n",
    "#print (train_dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_set,         # The dataset\n",
    "    batch_size=batch_size,    # Batch size\n",
    "    shuffle=True,      # Shuffles the dataset at every epoch\n",
    "    pin_memory=True,   \n",
    "    num_workers=num_workers)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_set,         # The dataset\n",
    "    batch_size=batch_size,    # Batch size\n",
    "    shuffle=False,      # Shuffles the dataset at every epoch\n",
    "    pin_memory=True,   \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, num_features, out_features):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_features, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2048),\n",
    "\n",
    "            nn.Linear(2048, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(0.1),\n",
    "\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            \n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "\n",
    "            nn.Linear(512, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        fan_in = m.weight.size()[1]\n",
    "        fan_out = m.weight.size()[0]\n",
    "        std = np.sqrt(2.0 / (fan_in + fan_out))\n",
    "        m.weight.data.normal_(0,std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 1st Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPModel(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=1240, out_features=2048, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): Dropout(p=0.1, inplace=False)\n",
      "    (7): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): Dropout(p=0.2, inplace=False)\n",
      "    (14): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (15): ReLU()\n",
      "    (16): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): Linear(in_features=512, out_features=138, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MLPModel(train_dataset.output_dim, len(train_dataset.outcomes))\n",
    "model.apply(init_xavier)\n",
    "model = model.float()\n",
    "model.cuda()\n",
    "print (model)\n",
    "\n",
    "AdamOptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(AdamOptimizer, step_size=8, gamma=0.1)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_losses = []\n",
    "mean_valid_losses = []\n",
    "valid_acc_list = []\n",
    "epochs = 12\n",
    "best_model = None\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    scheduler.step()\n",
    "    for x_batch, y_batch in tqdm(train_dataloader):\n",
    "        AdamOptimizer.zero_grad()\n",
    "        x_batch = x_batch.view(-1, (2*K+1)*40).cuda()\n",
    "        y_batch = y_batch.long().cuda()\n",
    "        outputs = model(x_batch.float())\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        AdamOptimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    valid_losses = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(val_dataloader):\n",
    "            x_batch = x_batch.view(-1, (2*K+1)*40).cuda()\n",
    "            y_batch = y_batch.long().cuda()\n",
    "            outputs = model(x_batch.float())\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            valid_losses.append(loss.item())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    \n",
    "    mean_train_losses.append(np.mean(train_losses))\n",
    "    mean_valid_losses.append(np.mean(valid_losses))\n",
    "    accuracy = 100*correct/total\n",
    "    if (best_model is None) or (accuracy > max(valid_acc_list)):\n",
    "        best_model = model\n",
    "    valid_acc_list.append(accuracy)\n",
    "    print('epoch {}: train loss : {:.4f}, valid loss : {:.4f}, valid acc : {:.2f}%'\\\n",
    "         .format(epoch+1, np.mean(train_losses), np.mean(valid_losses), accuracy))\n",
    "model_name = ('best_%d.pt'%int(time.time()))\n",
    "torch.save(best_model.state_dict(), MODEL_PATH+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build 2nd Model based on 1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel(train_dataset.output_dim, len(train_dataset.outcomes))\n",
    "model.load_state_dict(torch.load(MODEL_PATH+model_name))\n",
    "model.cuda()\n",
    "AdamOptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(AdamOptimizer, step_size=4, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d46d22e53c1c4d328674e85e1cf241b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfeb6af56d149828caf218e64a80f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1: train loss : 1.5741, valid loss : 1.4948, valid acc : 59.75%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d87faa04dbf42ba9203a279dbf48904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d4bd9641b64831aa6ecb4a06e1aeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 2: train loss : 1.5429, valid loss : 1.4777, valid acc : 60.15%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bdf47157284599a92db882e2a892f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39281e33f3c42f691f2b55b36d7673d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 3: train loss : 1.5147, valid loss : 1.4464, valid acc : 61.06%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380739f8c3364d56ab242ad32b10c92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490a5b8563a54d379481efcf2351cc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 4: train loss : 1.3974, valid loss : 1.3393, valid acc : 63.82%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa448919d91f412eb53f184a87c52a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15f42a34f0e74f4db7ee50083fc42ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 5: train loss : 1.3781, valid loss : 1.3297, valid acc : 64.03%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799ec653294b45dca58ad60307b093fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc5058a65814ae7bbf8cd45fe967183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 6: train loss : 1.3686, valid loss : 1.3219, valid acc : 64.25%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b435c48d09ff4cfb9a59500806571c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6652a9a344480f953aa9b8841137c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 7: train loss : 1.3614, valid loss : 1.3176, valid acc : 64.30%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474dc9a360004d21b70b12ba33782e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83157b55e704de8977a33e9a8691d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 8: train loss : 1.3461, valid loss : 1.3095, valid acc : 64.58%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d149035ca9f64c8497a723511113b7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7c7b012e8d4d6ead9a900b302e5d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 9: train loss : 1.3441, valid loss : 1.3084, valid acc : 64.59%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b7a500597249818e314f0a0ba20dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f57c4ac27a4b199a1a77c772634bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 10: train loss : 1.3434, valid loss : 1.3076, valid acc : 64.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506dfc0944f045f8b379050bca4423a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5808a335404e109473da4758aec8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 11: train loss : 1.3425, valid loss : 1.3068, valid acc : 64.61%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675791de66534b35a9991b0056dbe910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=112954), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d12bf0f7bd54cbdbb3382382bc5f931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12551), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 12: train loss : 1.3406, valid loss : 1.3065, valid acc : 64.62%\n"
     ]
    }
   ],
   "source": [
    "mean_train_losses = []\n",
    "mean_valid_losses = []\n",
    "valid_acc_list = []\n",
    "epochs = 12\n",
    "best_model = None\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    scheduler.step()\n",
    "    for x_batch, y_batch in tqdm(train_dataloader):\n",
    "        AdamOptimizer.zero_grad()\n",
    "        x_batch = x_batch.view(-1, (2*K+1)*40).cuda()\n",
    "        y_batch = y_batch.long().cuda()\n",
    "        outputs = model(x_batch.float())\n",
    "        loss = loss_fn(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        AdamOptimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    valid_losses = []\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in tqdm(val_dataloader):\n",
    "            x_batch = x_batch.view(-1, (2*K+1)*40).cuda()\n",
    "            y_batch = y_batch.long().cuda()\n",
    "            outputs = model(x_batch.float())\n",
    "            loss = loss_fn(outputs, y_batch)\n",
    "            valid_losses.append(loss.item())\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    \n",
    "    mean_train_losses.append(np.mean(train_losses))\n",
    "    mean_valid_losses.append(np.mean(valid_losses))\n",
    "    accuracy = 100*correct/total\n",
    "    if (best_model is None) or (accuracy > max(valid_acc_list)):\n",
    "        best_model = model\n",
    "    valid_acc_list.append(accuracy)\n",
    "    print('epoch {}: train loss : {:.4f}, valid loss : {:.4f}, valid acc : {:.2f}%'\\\n",
    "         .format(epoch+1, np.mean(train_losses), np.mean(valid_losses), accuracy))\n",
    "torch.save(best_model.state_dict(), MODEL_PATH+'best_%d.pt'%int(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of utterances 361\n",
      "Number of dimentions 40\n",
      "Avg length of utterances 619.3684210526316\n"
     ]
    }
   ],
   "source": [
    "test_x = load_data(DATA_PATH+\"test.npy\")\n",
    "test_dataset = MyDataset(K, test_x)\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, # The dataset\n",
    "    batch_size=batch_size,      # Batch size\n",
    "    shuffle=False,      # Shuffles the dataset at every epoch\n",
    "    pin_memory=True,   \n",
    "    num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a387c78e51b4dddbdaf7a76875e88f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1747), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   0    108\n",
       "1   1    108\n",
       "2   2    108\n",
       "3   3    108\n",
       "4   4    108"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.eval()\n",
    "test_preds = torch.LongTensor().cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch in tqdm(test_dataloader):\n",
    "        x_batch = x_batch.view(-1, (2*K+1)*40).cuda()\n",
    "        outputs = final_model(x_batch.float())\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        test_preds = torch.cat((test_preds, pred), dim=0)\n",
    "        \n",
    "out_df = pd.DataFrame()\n",
    "out_df['id'] = np.arange(0, len(test_dataset))\n",
    "out_df['label'] = test_preds.cpu().numpy()\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = SUBMISSION_PATH+\"submission_%d.csv\"%int(time.time())\n",
    "out_df.to_csv(file_name,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
